"""
Pipeline principal para an√°lise de risco de hipertens√£o.
Executa todo o workflow de Machine Learning do projeto.
"""

import argparse
import sys
from pathlib import Path
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# Adicionar src ao path
src_path = Path(__file__).parent / 'src'
sys.path.append(str(src_path))

from src.data.data_loader import HypertensionDataLoader
from src.data.preprocessor import MedicalDataPreprocessor
from src.data.feature_engineering import MedicalFeatureEngineer
from src.models.ensemble_models import HypertensionEnsemble
from src.evaluation.visualization import ModelVisualizer
from src.evaluation.medical_analysis import MedicalAnalyzer
from src.analysis.interpretability import ModelInterpreter
from src.utils.helpers import print_section
from src.utils.config import load_config


def run_complete_pipeline(data_path: str, quick_run: bool = False):
    """
    Executa pipeline completo de Machine Learning.
    
    Args:
        data_path: Caminho para o arquivo de dados
        quick_run: Se True, executa vers√£o r√°pida para testes
    """
    print_section("üöÄ INICIANDO PIPELINE COMPLETO DE ML - HIPERTENS√ÉO", "=", 80)
    
    config = load_config()
    
    # 1. CARREGAMENTO E EXPLORA√á√ÉO DOS DADOS
    print_section("üìä FASE 1: CARREGAMENTO E EXPLORA√á√ÉO DOS DADOS")
    
    loader = HypertensionDataLoader()
    df = loader.load_data(data_path)
    
    if df is None:
        print("‚ùå Erro ao carregar dados. Verifique o caminho do arquivo.")
        return False
    
    # EDA b√°sica
    eda_results = loader.perform_basic_eda(df)
    
    # 2. PR√â-PROCESSAMENTO DOS DADOS  
    print_section("üîß FASE 2: PR√â-PROCESSAMENTO DOS DADOS")
    
    preprocessor = MedicalDataPreprocessor()
    
    # Limpeza e valida√ß√£o
    df_clean = preprocessor.clean_and_validate(df)
    
    # Tratamento de valores ausentes
    df_processed = preprocessor.handle_missing_values(df_clean)
    
    # Detec√ß√£o de outliers
    outliers_info = preprocessor.detect_outliers(df_processed)
    
    # 3. FEATURE ENGINEERING
    print_section("‚öôÔ∏è FASE 3: FEATURE ENGINEERING")
    
    feature_engineer = MedicalFeatureEngineer()
    
    # Criar features m√©dicas especializadas
    df_features = feature_engineer.create_blood_pressure_features(df_processed)
    df_features = feature_engineer.create_cardiovascular_features(df_features)
    df_features = feature_engineer.create_risk_interaction_features(df_features)
    
    # Sele√ß√£o de features
    target_col = config['data']['target_column']
    selected_features = feature_engineer.select_features(
        df_features, target_col, 
        max_features=20 if quick_run else 30
    )
    
    # 4. TREINAMENTO DE MODELOS
    print_section("ü§ñ FASE 4: TREINAMENTO DE MODELOS")
    
    # Preparar dados para treinamento
    X = df_features[selected_features['selected_features']]
    y = df_features[target_col]
    
    # Treinar ensemble de modelos
    ensemble = HypertensionEnsemble()
    
    if quick_run:
        # Vers√£o r√°pida para testes
        results = ensemble.train_quick_ensemble(X, y)
    else:
        # Treinamento completo
        results = ensemble.train_complete_ensemble(X, y)
    
    # 5. AVALIA√á√ÉO E VISUALIZA√á√ÉO
    print_section("üìà FASE 5: AVALIA√á√ÉO E VISUALIZA√á√ÉO")
    
    visualizer = ModelVisualizer()
    
    # Criar visualiza√ß√µes dos modelos
    visualizer.create_model_comparison_plots(results)
    visualizer.create_feature_importance_plots(results, selected_features)
    
    # Salvar o melhor modelo
    best_model_path = ensemble.save_best_model(results)
    
    # 6. AN√ÅLISE M√âDICA
    print_section("üè• FASE 6: AN√ÅLISE M√âDICA ESPECIALIZADA")
    
    medical_analyzer = MedicalAnalyzer()
    medical_report = medical_analyzer.create_medical_report(df_features, target_col)
    
    # 7. INTERPRETABILIDADE
    print_section("üîç FASE 7: INTERPRETABILIDADE DO MODELO")
    
    if best_model_path and not quick_run:
        interpreter = ModelInterpreter()
        
        # Carregar dados de teste
        X_test = results['test_data']['X_test']
        y_test = results['test_data']['y_test']
        X_train = results['test_data']['X_train']
        
        # Carregar modelo e analisar
        interpreter.load_model_and_data(best_model_path, X_test, y_test, X_train)
        
        # An√°lise de import√¢ncia
        feature_importance = interpreter.analyze_feature_importance()
        
        # Criar explica√ß√µes SHAP
        shap_explanations = interpreter.create_shap_explanations(n_samples=100)
        
        # An√°lise de depend√™ncia parcial
        partial_dependence = interpreter.analyze_partial_dependence()
        
        # Criar visualiza√ß√µes
        interpreter.create_interpretation_visualizations()
        
        # Gerar relat√≥rio de interpretabilidade
        interpretation_report = interpreter.generate_interpretation_report()
    
    # 8. RELAT√ìRIO FINAL
    print_section("üìã FASE 8: RELAT√ìRIO FINAL", "=", 80)
    
    print("‚úÖ PIPELINE COMPLETO EXECUTADO COM SUCESSO!")
    print(f"üìä Dados processados: {len(df_features):,} amostras")
    print(f"üéØ Features selecionadas: {len(selected_features['selected_features'])}")
    print(f"ü§ñ Melhor modelo: {results['best_model']['name']} (Acur√°cia: {results['best_model']['accuracy']:.3f})")
    
    if best_model_path:
        print(f"üíæ Modelo salvo em: {best_model_path}")
    
    print(f"üìà Visualiza√ß√µes salvas em: {config['paths']['figures_dir']}")
    print(f"üìã Relat√≥rios salvos em: {config['paths']['reports_dir']}")
    
    # Resumo m√©dico
    dados_gerais = medical_report['dados_gerais']
    print(f"\nüè• RESUMO M√âDICO:")
    print(f"   ‚Ä¢ Preval√™ncia de hipertens√£o: {dados_gerais['prevalencia_hipertensao']:.1f}%")
    print(f"   ‚Ä¢ Idade m√©dia da popula√ß√£o: {dados_gerais['idade_media']:.1f} anos")
    print(f"   ‚Ä¢ Press√£o arterial m√©dia: {dados_gerais['pressao_sistolica_media']:.0f}/{dados_gerais['pressao_diastolica_media']:.0f} mmHg")
    
    print("\nüí° PR√ìXIMOS PASSOS:")
    print("   1. Revisar relat√≥rios m√©dicos gerados")
    print("   2. Validar insights cl√≠nicos com especialistas")
    print("   3. Implementar modelo em ambiente de produ√ß√£o")
    print("   4. Configurar monitoramento cont√≠nuo")
    
    return True


def run_quick_analysis(data_path: str):
    """
    Executa an√°lise r√°pida para verifica√ß√£o do pipeline.
    """
    print_section("‚ö° AN√ÅLISE R√ÅPIDA DO PIPELINE")
    
    try:
        return run_complete_pipeline(data_path, quick_run=True)
    except Exception as e:
        print(f"‚ùå Erro na an√°lise r√°pida: {e}")
        return False


def main():
    """
    Fun√ß√£o principal com interface de linha de comando.
    """
    parser = argparse.ArgumentParser(
        description="Pipeline de Machine Learning para An√°lise de Risco de Hipertens√£o",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python main.py dados.csv                    # Pipeline completo
  python main.py dados.csv --quick           # An√°lise r√°pida
  python main.py --demo                      # Dados de demonstra√ß√£o
        """
    )
    
    parser.add_argument(
        'data_file', 
        nargs='?',
        help='Caminho para o arquivo de dados CSV'
    )
    
    parser.add_argument(
        '--quick', 
        action='store_true',
        help='Executar vers√£o r√°pida do pipeline (para testes)'
    )
    
    parser.add_argument(
        '--demo', 
        action='store_true',
        help='Executar com dados de demonstra√ß√£o'
    )
    
    args = parser.parse_args()
    
    # Verificar argumentos
    if args.demo:
        # Usar dados de demonstra√ß√£o do notebook
        data_path = "notebooks/Hypertension-risk-model-main.csv"
    elif args.data_file:
        data_path = args.data_file
    else:
        print("‚ùå Erro: Especifique um arquivo de dados ou use --demo")
        parser.print_help()
        return
    
    # Verificar se arquivo existe
    if not Path(data_path).exists():
        print(f"‚ùå Erro: Arquivo n√£o encontrado: {data_path}")
        return
    
    # Executar pipeline
    if args.quick:
        success = run_quick_analysis(data_path)
    else:
        success = run_complete_pipeline(data_path)
    
    if success:
        print("\nüéâ Pipeline executado com sucesso!")
    else:
        print("\n‚ùå Pipeline falhou. Verifique os logs para detalhes.")


if __name__ == "__main__":
    main()