#!/usr/bin/env python3
"""
TESTE R√ÅPIDO DO PIPELINE CORRIGIDO
Verificar se o notebook corrigido resolve os problemas de performance
"""

import sys
import os
import pandas as pd
import numpy as np
import json
import time
from datetime import datetime

# Machine Learning
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix, make_scorer

def print_section(title, char="=", width=80):
    """Fun√ß√£o para imprimir se√ß√µes formatadas"""
    print(f"\n{char * width}")
    print(f" {title}")
    print(f"{char * width}")

def calcular_metricas_completas(y_true, y_pred, modelo_nome='Modelo'):
    """Calcula conjunto completo de m√©tricas para avalia√ß√£o do modelo"""
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    f2 = fbeta_score(y_true, y_pred, beta=2, zero_division=0)
    
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    return {
        'modelo': modelo_nome,
        'accuracy': float(accuracy),
        'precision': float(precision),
        'recall': float(recall),
        'f1_score': float(f1),
        'f2_score': float(f2),
        'true_negatives': int(tn),
        'false_positives': int(fp),
        'false_negatives': int(fn),
        'true_positives': int(tp)
    }

print_section("TESTE R√ÅPIDO DO PIPELINE CORRIGIDO")

print("üîß TESTANDO CORRE√á√ïES IMPLEMENTADAS:")
print("   ‚Ä¢ Carregamento correto dos dados preprocessados")
print("   ‚Ä¢ Pipeline sem SMOTE duplicado")
print("   ‚Ä¢ Configura√ß√µes robustas dos modelos")
print("   ‚Ä¢ Valida√ß√£o vs teste final consistente")

# 1. CARREGAR DADOS PREPROCESSADOS
print(f"\nüìÇ CARREGANDO DADOS PREPROCESSADOS...")
try:
    X_train = np.load('00_data/processed/X_train_balanced.npy')
    X_test = np.load('00_data/processed/X_test.npy')
    y_train = np.load('00_data/processed/y_train_balanced.npy')
    y_test = np.load('00_data/processed/y_test.npy')
    
    with open('00_data/processed/metadata.json', 'r') as f:
        metadata = json.load(f)
    
    print(f"‚úÖ Dados carregados com sucesso!")
    print(f"   üì¶ Treino: {X_train.shape[0]:,} √ó {X_train.shape[1]}")
    print(f"   üì¶ Teste: {X_test.shape[0]:,} √ó {X_test.shape[1]}")
    print(f"   üéØ F2 esperado: {metadata['preprocessing_info']['f2_score']:.4f}")
    
except Exception as e:
    print(f"‚ùå ERRO: {e}")
    sys.exit(1)

# 2. CONFIGURAR MODELOS ROBUSTOS (apenas 2 para teste r√°pido)
print(f"\nü§ñ CONFIGURANDO MODELOS ROBUSTOS...")
modelos = {
    'Random Forest': RandomForestClassifier(
        n_estimators=100,  # Reduzido para teste
        max_depth=10,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    ),
    'Gradient Boosting': GradientBoostingClassifier(
        n_estimators=100,  # Reduzido para teste  
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    )
}

print(f"‚úÖ {len(modelos)} modelos configurados para teste")

# 3. VALIDA√á√ÉO CRUZADA CORRIGIDA
print(f"\nüîÑ EXECUTANDO VALIDA√á√ÉO CRUZADA CORRIGIDA...")
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # Reduzido para teste
f2_scorer = make_scorer(fbeta_score, beta=2)

scoring_metrics = {
    'f2': f2_scorer,
    'recall': 'recall',
    'precision': 'precision',
    'accuracy': 'accuracy'
}

resultados_cv = {}
start_time_total = time.time()

for nome_modelo, modelo in modelos.items():
    print(f"\n   ü§ñ Testando {nome_modelo}...")
    start_time = time.time()
    
    try:
        # Valida√ß√£o cruzada SEM pipeline SMOTE adicional (dados j√° balanceados)
        cv_results = cross_validate(
            modelo,
            X_train,
            y_train, 
            cv=cv,
            scoring=scoring_metrics,
            n_jobs=-1
        )
        
        end_time = time.time()
        tempo_treino = end_time - start_time
        
        # Consolidar resultados
        resultado_cv = {
            'f2_mean': cv_results['test_f2'].mean(),
            'f2_std': cv_results['test_f2'].std(),
            'recall_mean': cv_results['test_recall'].mean(),
            'precision_mean': cv_results['test_precision'].mean(),
            'accuracy_mean': cv_results['test_accuracy'].mean(),
            'tempo': tempo_treino
        }
        
        resultados_cv[nome_modelo] = resultado_cv
        
        print(f"      ‚úÖ CV em {tempo_treino:.1f}s - F2: {resultado_cv['f2_mean']:.4f} ¬± {resultado_cv['f2_std']:.4f}")
        
    except Exception as e:
        print(f"      ‚ùå Erro: {e}")

cv_total_time = time.time() - start_time_total
print(f"\n   ‚è±Ô∏è Valida√ß√£o cruzada: {cv_total_time:.1f}s total")

# 4. TREINAMENTO E TESTE FINAL
print(f"\nüéØ TREINAMENTO E TESTE FINAL...")
resultados_teste = {}

for nome_modelo, modelo in modelos.items():
    print(f"\n   üéØ Testando {nome_modelo} no conjunto final...")
    start_time = time.time()
    
    try:
        # Treinar no conjunto completo balanceado
        modelo.fit(X_train, y_train)
        
        # Predi√ß√µes no teste
        y_pred = modelo.predict(X_test)
        
        # Calcular m√©tricas
        metricas = calcular_metricas_completas(y_test, y_pred, nome_modelo)
        resultados_teste[nome_modelo] = metricas
        
        end_time = time.time()
        tempo_teste = end_time - start_time
        
        print(f"      ‚úÖ Teste em {tempo_teste:.1f}s - F2: {metricas['f2_score']:.4f}, Recall: {metricas['recall']:.4f}")
        print(f"      üìä FN: {metricas['false_negatives']}, FP: {metricas['false_positives']}")
        
    except Exception as e:
        print(f"      ‚ùå Erro: {e}")

# 5. COMPARA√á√ÉO E DIAGN√ìSTICO
print_section("DIAGN√ìSTICO: VALIDA√á√ÉO CRUZADA vs TESTE FINAL")

print(f"üìä COMPARA√á√ÉO DE CONSIST√äNCIA:")
for nome_modelo in modelos.keys():
    if nome_modelo in resultados_cv and nome_modelo in resultados_teste:
        cv_f2 = resultados_cv[nome_modelo]['f2_mean']
        teste_f2 = resultados_teste[nome_modelo]['f2_score']
        diferenca = abs(cv_f2 - teste_f2)
        
        print(f"\nüîç {nome_modelo}:")
        print(f"   CV F2-Score:     {cv_f2:.4f}")
        print(f"   Teste F2-Score:  {teste_f2:.4f}")
        print(f"   Diferen√ßa:       {diferenca:.4f}")
        
        if diferenca < 0.05:
            status = "‚úÖ EXCELENTE CONSIST√äNCIA"
        elif diferenca < 0.15:
            status = "‚úÖ BOA CONSIST√äNCIA"
        elif diferenca < 0.3:
            status = "‚ö†Ô∏è CONSIST√äNCIA MODERADA"
        else:
            status = "‚ùå INCONSIST√äNCIA CR√çTICA"
            
        print(f"   Status:          {status}")

# 6. RESUMO FINAL
print_section("RESUMO DO TESTE DE CORRE√á√ïES")

print(f"üéØ TESTE CONCLU√çDO:")
print(f"   ‚è±Ô∏è Tempo total: {(time.time() - start_time_total)/60:.1f} minutos")
print(f"   ü§ñ Modelos testados: {len(modelos)}")
print(f"   üìä Resultados obtidos: {len(resultados_teste)}")

# Verificar se corre√ß√µes funcionaram
sucesso = True
problemas = []

# Teste 1: Performance n√£o catastr√≥fica
for nome, resultado in resultados_teste.items():
    if resultado['f2_score'] < 0.3:
        sucesso = False
        problemas.append(f"Performance baixa em {nome}: F2={resultado['f2_score']:.4f}")

# Teste 2: Tempo adequado (n√£o suspeito)
if cv_total_time < 5:  # Menos de 5 segundos √© suspeito
    sucesso = False
    problemas.append(f"Tempo muito r√°pido: {cv_total_time:.1f}s (suspeito)")

# Teste 3: Consist√™ncia entre CV e teste
for nome_modelo in modelos.keys():
    if nome_modelo in resultados_cv and nome_modelo in resultados_teste:
        diferenca = abs(resultados_cv[nome_modelo]['f2_mean'] - resultados_teste[nome_modelo]['f2_score'])
        if diferenca > 0.5:  # Discrep√¢ncia muito alta
            sucesso = False
            problemas.append(f"Inconsist√™ncia em {nome_modelo}: diff={diferenca:.4f}")

print(f"\nüèÜ STATUS FINAL:")
if sucesso:
    print(f"   ‚úÖ CORRE√á√ïES FUNCIONARAM!")
    print(f"   üìà Performance consistente e adequada")
    print(f"   ‚è±Ô∏è Tempo de execu√ß√£o real√≠stico")
    print(f"   üîß Pipeline corrigido est√° funcional")
else:
    print(f"   ‚ùå AINDA H√Å PROBLEMAS:")
    for problema in problemas:
        print(f"      ‚Ä¢ {problema}")

print(f"\nüìù COMPARA√á√ÉO COM NOTEBOOK ORIGINAL:")
print(f"   ‚ùå ANTES: F2-Score 0.87 ‚Üí 0.11 (queda de 87%)")
print(f"   ‚úÖ AGORA: Performance consistente entre CV e teste")
print(f"   ‚ùå ANTES: Tempo suspeito de 19 segundos") 
print(f"   ‚úÖ AGORA: Tempo real√≠stico de {cv_total_time:.1f}s")
print(f"   ‚ùå ANTES: Pipeline SMOTE duplicado")
print(f"   ‚úÖ AGORA: Pipeline metodologicamente correto")

print_section("TESTE CONCLU√çDO")