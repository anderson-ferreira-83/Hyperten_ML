<!DOCTYPE html>

<html lang="pt-BR">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial Completo - TÃ©cnicas AvanÃ§adas de ML</title>
<style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 36px;
            margin-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }

        .header p {
            font-size: 18px;
            opacity: 0.95;
        }

        .tabs-container {
            display: flex;
            background: #f5f5f5;
            border-bottom: 3px solid #667eea;
            overflow-x: auto;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .tab {
            flex: 1;
            min-width: 200px;
            padding: 20px;
            background: #f5f5f5;
            border: none;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            color: #666;
            transition: all 0.3s ease;
            position: relative;
            text-align: center;
        }

        .tab:hover {
            background: #e8e8e8;
            color: #667eea;
        }

        .tab.active {
            background: white;
            color: #667eea;
            border-bottom: 4px solid #667eea;
        }

        .tab-number {
            display: inline-block;
            width: 30px;
            height: 30px;
            line-height: 30px;
            border-radius: 50%;
            background: #ddd;
            color: #666;
            margin-right: 10px;
            font-weight: bold;
        }

        .tab.active .tab-number {
            background: #667eea;
            color: white;
        }

        .tab.completed .tab-number {
            background: #4CAF50;
            color: white;
        }

        .tab.completed .tab-number::after {
            content: 'âœ“';
        }

        .content-container {
            padding: 40px;
        }

        .tab-content {
            display: none;
            animation: fadeIn 0.5s ease;
        }

        .tab-content.active {
            display: block;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section-title {
            font-size: 28px;
            color: #333;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }

        .subsection-title {
            font-size: 22px;
            color: #444;
            margin-top: 30px;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
        }

        .subsection-title::before {
            content: 'â–¶';
            color: #667eea;
            margin-right: 10px;
            font-size: 18px;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 5px solid #2196F3;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .info-box h4 {
            color: #1976d2;
            margin-bottom: 10px;
            font-size: 18px;
        }

        .warning-box {
            background: #fff3e0;
            border-left: 5px solid #ff9800;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .warning-box h4 {
            color: #f57c00;
            margin-bottom: 10px;
            font-size: 18px;
        }

        .success-box {
            background: #e8f5e9;
            border-left: 5px solid #4CAF50;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .success-box h4 {
            color: #2e7d32;
            margin-bottom: 10px;
            font-size: 18px;
        }

        .critical-box {
            background: #ffebee;
            border-left: 5px solid #f44336;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .critical-box h4 {
            color: #c62828;
            margin-bottom: 10px;
            font-size: 18px;
        }

        .code-block {
            background: #263238;
            color: #aed581;
            padding: 25px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
            position: relative;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        .code-block::before {
            content: 'Python';
            position: absolute;
            top: 10px;
            right: 10px;
            background: #667eea;
            color: white;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 11px;
            font-weight: bold;
        }

        .code-comment {
            color: #80cbc4;
        }

        .code-string {
            color: #ffab91;
        }

        .code-keyword {
            color: #81d4fa;
            font-weight: bold;
        }

        .code-function {
            color: #fff59d;
        }

        .step-card {
            background: white;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 25px;
            margin: 20px 0;
            transition: all 0.3s ease;
        }

        .step-card:hover {
            border-color: #667eea;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.2);
            transform: translateY(-2px);
        }

        .step-number {
            display: inline-block;
            width: 40px;
            height: 40px;
            line-height: 40px;
            border-radius: 50%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-align: center;
            font-weight: bold;
            font-size: 18px;
            margin-right: 15px;
            float: left;
        }

        .step-content {
            overflow: hidden;
        }

        .step-title {
            font-size: 20px;
            color: #333;
            margin-bottom: 10px;
            font-weight: 600;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .comparison-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }

        .comparison-table td {
            padding: 12px 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .comparison-table tr:nth-child(even) {
            background: #f9f9f9;
        }

        .comparison-table tr:hover {
            background: #f0f0f0;
        }

        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .pros, .cons {
            padding: 20px;
            border-radius: 10px;
        }

        .pros {
            background: #e8f5e9;
            border: 2px solid #4CAF50;
        }

        .pros h4 {
            color: #2e7d32;
            margin-bottom: 15px;
        }

        .cons {
            background: #ffebee;
            border: 2px solid #f44336;
        }

        .cons h4 {
            color: #c62828;
            margin-bottom: 15px;
        }

        .visual-diagram {
            background: #f5f5f5;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 30px;
            margin: 25px 0;
            text-align: center;
        }

        .diagram-title {
            font-size: 18px;
            font-weight: 600;
            color: #667eea;
            margin-bottom: 20px;
        }

        .navigation-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e0e0e0;
        }

        .nav-button {
            padding: 15px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .nav-button.prev {
            background: #e0e0e0;
            color: #666;
        }

        .nav-button.prev:hover {
            background: #d0d0d0;
        }

        .nav-button.next {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .nav-button.next:hover {
            transform: translateX(5px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .nav-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.5s ease;
            border-radius: 10px;
        }

        .key-takeaway {
            background: linear-gradient(135deg, #fff59d 0%, #ffd54f 100%);
            border: 2px solid #fbc02d;
            border-radius: 10px;
            padding: 25px;
            margin: 25px 0;
        }

        .key-takeaway h4 {
            color: #f57f17;
            margin-bottom: 15px;
            font-size: 20px;
            display: flex;
            align-items: center;
        }

        .key-takeaway h4::before {
            content: 'ğŸ’¡';
            margin-right: 10px;
            font-size: 24px;
        }

        ul, ol {
            margin-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 10px;
            line-height: 1.6;
        }

        p {
            line-height: 1.8;
            margin-bottom: 15px;
            color: #444;
        }

        .highlight {
            background: #fff59d;
            padding: 2px 5px;
            border-radius: 3px;
            font-weight: 600;
        }

        .formula {
            background: white;
            border: 2px solid #667eea;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            text-align: center;
            font-size: 16px;
        }

        @media (max-width: 768px) {
            .tabs-container {
                flex-wrap: wrap;
            }

            .tab {
                min-width: 150px;
            }

            .pros-cons {
                grid-template-columns: 1fr;
            }

            .content-container {
                padding: 20px;
            }

            .header h1 {
                font-size: 28px;
            }
        }

        @media print {
            body {
                background: white;
            }

            .tabs-container, .navigation-buttons {
                display: none;
            }

            .tab-content {
                display: block !important;
            }
        }
    

/* ===== Overrides orientador (sÃ³brias) ===== */
:root {
  --bg: #f7f7f8;
  --paper: #ffffff;
  --ink: #111827;          /* slate-900 */
  --muted: #4b5563;        /* slate-600 */
  --line: #e5e7eb;         /* gray-200 */
  --accent: #334155;       /* slate-700 */
  --accent-strong: #1f2937;/* slate-800 */
}

body {
  background: var(--bg) !important;
  color: var(--ink) !important;
}

.container {
  background: var(--paper) !important;
  box-shadow: 0 10px 30px rgba(0,0,0,0.12) !important;
}

.header {
  background: var(--accent-strong) !important;
}

.tabs-container {
  background: #f3f4f6 !important;
  border-bottom: 3px solid var(--accent) !important;
}

.tab {
  color: var(--muted) !important;
}

.tab:hover {
  color: var(--accent) !important;
  background: #eef2f7 !important;
}

.tab.active {
  background: var(--paper) !important;
  color: var(--accent) !important;
  border-bottom: 4px solid var(--accent) !important;
}

.tab-number {
  background: #d1d5db !important;
  color: var(--ink) !important;
}

/* Remover Ã­cones decorativos */
.subsection-title::before,
.key-takeaway h4::before,
.tab.completed .tab-number::after {
  content: "" !important;
}

/* TÃ­tulos e divisores */
.section-title {
  color: var(--accent-strong) !important;
  border-bottom: 3px solid var(--accent) !important;
}

.step-card {
  border: 1px solid var(--line) !important;
}

.info-box {
  background: #eef2f7 !important;
  border-left: 5px solid var(--accent) !important;
}

.warning-box {
  background: #fff7ed !important; /* light amber-like */
  border-left: 5px solid #b45309 !important;
}

.success-box {
  background: #f0fdf4 !important;
  border-left: 5px solid #15803d !important;
}

.critical-box {
  background: #fef2f2 !important;
  border-left: 5px solid #b91c1c !important;
}

/* CÃ³digo: fundo branco, texto escuro, indentaÃ§Ã£o preservada */
.code-block {
  background: #ffffff !important;
  color: #111827 !important;
  border: 1px solid var(--line) !important;
  font-family: Consolas, "Courier New", monospace !important;
  white-space: pre !important;           /* preserva identaÃ§Ã£o */
  line-height: 1.5 !important;
}

.code-block::before {
  background: var(--accent) !important;
  color: #ffffff !important;
}

.code-comment { color: #6b7280 !important; }
.code-keyword  { color: #1f2937 !important; font-weight: 700 !important; }
.code-string   { color: #0f172a !important; }
.code-function { color: #111827 !important; }

/* Tabelas */
.comparison-table th {
  background: var(--accent) !important;
}

.comparison-table tr:nth-child(even) {
  background: #f9fafb !important;
}

.visual-diagram {
  background: #f9fafb !important;
  border: 1px solid var(--line) !important;
}

/* Destaques mais sÃ³brios */
.key-takeaway {
  background: #fafaf9 !important;
  border: 1px solid var(--line) !important;
}

.highlight {
  background: #fffce8 !important;
}

/* Buttons navegaÃ§Ã£o mais discretos */
.nav-button.prev {
  background: #e5e7eb !important;
  color: var(--ink) !important;
}
.nav-button.next {
  background: var(--accent) !important;
  color: #ffffff !important;
}
.nav-button.next:hover {
  box-shadow: 0 4px 10px rgba(31,41,55,0.25) !important;
}

/* Print */
@media print {
  .tab { border: none !important; }
}


/* ===== Preset Preto & Branco (minimal) ===== */
:root {
  --bg: #ffffff;
  --paper: #ffffff;
  --ink: #111111;
  --muted: #444444;
  --line: #d9d9d9;
  --accent: #111111;
  --accent-strong: #000000;
}

body {
  background: var(--bg) !important;
  color: var(--ink) !important;
  -webkit-print-color-adjust: exact !important;
  print-color-adjust: exact !important;
}

.container {
  background: var(--paper) !important;
  box-shadow: none !important;
  border: 1px solid var(--line) !important;
}

.header { 
  background: #000 !important;
  color: #fff !important;
}

.header h1, .header p { color: #fff !important; }

.tabs-container {
  background: #fff !important;
  border-bottom: 1px solid var(--line) !important;
}

.tab {
  color: var(--muted) !important;
  background: #fff !important;
  border: 1px solid var(--line) !important;
}

.tab.active {
  background: #fff !important;
  color: #000 !important;
  border-bottom: 2px solid #000 !important;
}

.tab-number {
  background: #eaeaea !important;
  color: #000 !important;
}

/* TÃ­tulos e divisores */
.section-title {
  color: #000 !important;
  border-bottom: 2px solid #000 !important;
}

h2, h3, h4 { color: #000 !important; }

/* Cards e caixas */
.step-card, .info-box, .warning-box, .success-box, .critical-box, .key-takeaway {
  background: #fff !important;
  border: 1px solid var(--line) !important;
}

.warning-box, .success-box, .critical-box { border-left-width: 3px !important; }

/* CÃ³digo */
.code-block {
  background: #ffffff !important;
  color: #111111 !important;
  border: 1px solid var(--line) !important;
  font-family: Consolas, "Courier New", monospace !important;
  white-space: pre !important;         /* preserva identaÃ§Ã£o */
  line-height: 1.5 !important;
}

/* RÃ³tulo do bloco de cÃ³digo usa o data-label dinÃ¢mico */
.code-block::before {
  content: attr(data-label) !important;
  display: block;
  padding: 6px 10px;
  border-bottom: 1px solid var(--line);
  background: #f6f6f6;
  color: #000;
  font-size: 12px;
  font-weight: 600;
}

/* Tabelas */
.comparison-table th {
  background: #000 !important;
  color: #fff !important;
}
.comparison-table tr:nth-child(even) {
  background: #fafafa !important;
}

/* Diagramas */
.visual-diagram {
  background: #fff !important;
  border: 1px solid var(--line) !important;
}

/* BotÃµes discretos */
.nav-button {
  border: 1px solid var(--line) !important;
  background: #fff !important;
  color: #000 !important;
  box-shadow: none !important;
}

/* Print */
@media print {
  .tab, .tabs-container { border: none !important; }
  a { color: #000 !important; text-decoration: underline !important; }
}
</style>
</head>
<body>
<div class="container">
<div class="header">
<h1>Tutorial Completo: TÃ©cnicas AvanÃ§adas de Machine Learning â€” OrientaÃ§Ãµes do Orientador</h1>
<p>Guia Sequencial e DidÃ¡tico para Aprimoramento do TCC de PrediÃ§Ã£o de HipertensÃ£o</p>
<div class="progress-bar">
<div class="progress-fill" id="progressBar" style="width: 20%;"></div>
</div>
</div>
<div class="tabs-container">
<button class="tab active" onclick="openTab(event, 'tab1')">
<span class="tab-number">1</span>
<span>IntroduÃ§Ã£o</span>
</button>
<button class="tab" onclick="openTab(event, 'tab2')">
<span class="tab-number">2</span>
<span>SMOTE</span>
</button>
<button class="tab" onclick="openTab(event, 'tab3')">
<span class="tab-number">3</span>
<span>ProporÃ§Ãµes de Treino</span>
</button>
<button class="tab" onclick="openTab(event, 'tab4')">
<span class="tab-number">4</span>
<span>K-Fold</span>
</button>
<button class="tab" onclick="openTab(event, 'tab5')">
<span class="tab-number">5</span>
<span>ValidaÃ§Ã£o Cruzada</span>
</button>
<button class="tab" onclick="openTab(event, 'tab6')">
<span class="tab-number">6</span>
<span>ImplementaÃ§Ã£o Final</span>
</button>
</div>
<div class="content-container">
<!-- TAB 1: INTRODUÃ‡ÃƒO -->
<div class="tab-content active" id="tab1">
<h2 class="section-title">Siga estas orientaÃ§Ãµes para elevar a qualidade metodolÃ³gica do seu trabalho. â€” OrientaÃ§Ã£o do orientador</h2><div class="info-box"><h4>Diretriz do orientador</h4><p>Como seu orientador, oriento que vocÃª siga este material na ordem proposta. A cada etapa, valide resultados, documente decisÃµes e mantenha reprodutibilidade. O objetivo Ã© aprimorar o rigor metodolÃ³gico do seu TCC sem alterar o escopo do problema.</p></div>
<div class="info-box">
<h4> O que vocÃª vai aprender neste tutorial</h4>
<p>Este tutorial foi cuidadosamente estruturado para apresentar, de forma progressiva e didÃ¡tica, quatro tÃ©cnicas essenciais que irÃ£o <strong>elevar significativamente a qualidade do seu TCC</strong>:</p>
<ol>
<li><strong>SMOTE</strong> - TÃ©cnica avanÃ§ada de balanceamento de classes</li>
<li><strong>Diferentes ProporÃ§Ãµes de Treino/Teste</strong> - OtimizaÃ§Ã£o da divisÃ£o de dados</li>
<li><strong>K-Fold Cross-Validation</strong> - ValidaÃ§Ã£o robusta do modelo</li>
<li><strong>ValidaÃ§Ã£o Cruzada Estratificada</strong> - Garantia de representatividade</li>
</ol>
</div>
<h3 class="subsection-title">Por Que Estas TÃ©cnicas SÃ£o Importantes? â€” OrientaÃ§Ã£o do orientador</h3>
<div class="step-card">
<div class="step-number">1</div>
<div class="step-content">
<div class="step-title">DiagnÃ³stico do trabalho atual</div>
<p>Atualmente, o TCC utiliza:</p>
<ul>
<li><strong>RandomOverSampler</strong> - tÃ©cnica bÃ¡sica que apenas duplica amostras</li>
<li><strong>DivisÃ£o simples 75/25</strong> - sem testar outras proporÃ§Ãµes</li>
<li><strong>ValidaÃ§Ã£o Ãºnica</strong> - resultados podem ser instÃ¡veis</li>
</ul>
<p style="color: #c62828; font-weight: 600;">Risco: Resultados podem nÃ£o ser confiÃ¡veis ou generalizÃ¡veis!</p>
</div>
</div>
<div class="step-card">
<div class="step-number">2</div>
<div class="step-content">
<div class="step-title">OrientaÃ§Ã£o</div>
<p>Implementar tÃ©cnicas avanÃ§adas que garantem:</p>
<ul>
<li> <strong>Melhor balanceamento</strong> com amostras sintÃ©ticas (SMOTE)</li>
<li> <strong>OtimizaÃ§Ã£o</strong> da proporÃ§Ã£o treino/teste</li>
<li> <strong>ValidaÃ§Ã£o robusta</strong> com mÃºltiplas iteraÃ§Ãµes (K-Fold)</li>
<li> <strong>Resultados confiÃ¡veis</strong> e generalizÃ¡veis</li>
</ul>
</div>
</div>
<h3 class="subsection-title">Fluxo de Aprendizado â€” OrientaÃ§Ã£o do orientador</h3>
<div class="visual-diagram">
<div class="diagram-title">SequÃªncia DidÃ¡tica do Tutorial</div>
<pre class="code-block" data-label="CÃ³digo" style="font-family: monospace; text-align: left; display: inline-block; line-height: 2;">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 1: INTRODUÃ‡ÃƒO                                          â”‚
â”‚  â””â”€ Entender o panorama geral e importÃ¢ncia                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 2: SMOTE                                               â”‚
â”‚  â””â”€ Aprender balanceamento avanÃ§ado                         â”‚
â”‚     â€¢ O que Ã© e como funciona                               â”‚
â”‚     â€¢ Vantagens sobre RandomOverSampler                     â”‚
â”‚     â€¢ CÃ³digo prÃ¡tico                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 3: PROPORÃ‡Ã•ES DE TREINO/TESTE                          â”‚
â”‚  â””â”€ Otimizar divisÃ£o de dados                               â”‚
â”‚     â€¢ Testar 60/40, 70/30, 75/25, 80/20                     â”‚
â”‚     â€¢ Comparar resultados                                   â”‚
â”‚     â€¢ Escolher melhor proporÃ§Ã£o                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 4: K-FOLD CROSS-VALIDATION                             â”‚
â”‚  â””â”€ ValidaÃ§Ã£o robusta e estÃ¡vel                             â”‚
â”‚     â€¢ Conceito de K-Fold                                    â”‚
â”‚     â€¢ Por que Ã© melhor que divisÃ£o Ãºnica                    â”‚
â”‚     â€¢ ImplementaÃ§Ã£o prÃ¡tica                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 5: VALIDAÃ‡ÃƒO CRUZADA ESTRATIFICADA                     â”‚
â”‚  â””â”€ Garantir representatividade                             â”‚
â”‚     â€¢ Stratified K-Fold                                     â”‚
â”‚     â€¢ ImportÃ¢ncia para dados desbalanceados                 â”‚
â”‚     â€¢ Boas prÃ¡ticas                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tab 6: IMPLEMENTAÃ‡ÃƒO FINAL INTEGRADA                       â”‚
â”‚  â””â”€ CÃ³digo completo unificado                               â”‚
â”‚     â€¢ Pipeline completo                                     â”‚
â”‚     â€¢ Todas as tÃ©cnicas integradas                          â”‚
â”‚     â€¢ Pronto para usar no TCC                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
</div>
<h3 class="subsection-title">Resultados esperados â€” OrientaÃ§Ã£o do orientador</h3>
<div class="success-box">
<h4> Melhorias Esperadas</h4>
<table class="comparison-table">
<thead>
<tr>
<th>Aspecto</th>
<th>Antes (Atual)</th>
<th>Depois (Com TÃ©cnicas)</th>
<th>Ganho</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sensibilidade</strong></td>
<td>~88%</td>
<td>~92-95%</td>
<td style="color: #2e7d32; font-weight: bold;">+4-7%</td>
</tr>
<tr>
<td><strong>F2-Score</strong></td>
<td>~0.87</td>
<td>~0.90-0.93</td>
<td style="color: #2e7d32; font-weight: bold;">+3-6%</td>
</tr>
<tr>
<td><strong>Confiabilidade</strong></td>
<td>1 divisÃ£o</td>
<td>5-10 validaÃ§Ãµes</td>
<td style="color: #2e7d32; font-weight: bold;">Muito maior</td>
</tr>
<tr>
<td><strong>Qualidade MetodolÃ³gica</strong></td>
<td>BÃ¡sica</td>
<td>AvanÃ§ada</td>
<td style="color: #2e7d32; font-weight: bold;">Significativa</td>
</tr>
<tr>
<td><strong>Rigor CientÃ­fico</strong></td>
<td>Adequado</td>
<td>Excelente</td>
<td style="color: #2e7d32; font-weight: bold;">Estado-da-arte</td>
</tr>
</tbody>
</table>
</div>
<h3 class="subsection-title">Como seguir estas orientaÃ§Ãµes â€” OrientaÃ§Ã£o do orientador</h3>
<div class="warning-box">
<h4>ï¸ Importante: Siga a SequÃªncia!</h4>
<p>As tÃ©cnicas sÃ£o apresentadas em ordem <strong>progressiva e lÃ³gica</strong>. Cada tab constrÃ³i sobre o conhecimento anterior:</p>
<ul>
<li> Primeiro aprenda <strong>SMOTE</strong> (balanceamento)</li>
<li> Depois entenda <strong>proporÃ§Ãµes</strong> (divisÃ£o de dados)</li>
<li> Em seguida domÃ­nio <strong>K-Fold</strong> (validaÃ§Ã£o mÃºltipla)</li>
<li> Finalmente aplique <strong>estratificaÃ§Ã£o</strong> (garantia de qualidade)</li>
<li> Por Ãºltimo integre <strong>tudo junto</strong> (implementaÃ§Ã£o final)</li>
</ul>
<p style="margin-top: 15px; font-weight: 600;"> NÃ£o pule etapas! Cada conceito Ã© essencial para entender o prÃ³ximo.</p>
</div>
<div class="key-takeaway">
<h4>Resumo orientativo</h4>
<ul>
<li> Seu TCC atual usa tÃ©cnicas <strong>bÃ¡sicas</strong> que podem ser significativamente melhoradas</li>
<li> Este tutorial apresenta <strong>4 tÃ©cnicas avanÃ§adas</strong> que elevarÃ£o a qualidade</li>
<li> As tÃ©cnicas sÃ£o apresentadas de forma <strong>sequencial e didÃ¡tica</strong></li>
<li> Espera-se ganho de <strong>4-7% em Sensibilidade</strong> e <strong>muito maior confiabilidade</strong></li>
<li> Tempo estimado: <strong>3-4 horas</strong> para completar todo o tutorial</li>
</ul>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" disabled="">
                        â† Anterior
                    </button>
<button class="nav-button next" onclick="nextTab()">
                        PrÃ³ximo: SMOTE â†’
                    </button>
</div>
</div>
<!-- TAB 2: SMOTE -->
<div class="tab-content" id="tab2">
<h2 class="section-title">TÃ©cnica 1: SMOTE - Synthetic Minority Over-sampling â€” OrientaÃ§Ã£o do orientador</h2>
<div class="info-box">
<h4>OrientaÃ§Ã£o desta seÃ§Ã£o</h4>
<p>Aprender a substituir <strong>RandomOverSampler</strong> (duplicaÃ§Ã£o simples) por <strong>SMOTE</strong> (criaÃ§Ã£o de amostras sintÃ©ticas), resultando em melhor generalizaÃ§Ã£o e reduÃ§Ã£o de overfitting.</p>
</div>
<h3 class="subsection-title">O Problema com RandomOverSampler (TÃ©cnica Atual) â€” OrientaÃ§Ã£o do orientador</h3>
<div class="critical-box">
<h4> LimitaÃ§Ãµes do RandomOverSampler</h4>
<p><strong>O que ele faz:</strong> Simplesmente <strong>duplica</strong> amostras existentes da classe minoritÃ¡ria atÃ© balancear.</p>
<p style="margin-top: 15px;"><strong>Exemplo:</strong></p>
<div class="code-block" data-label="CÃ³digo">
# Amostra original da classe minoritÃ¡ria
paciente_1 = [45, 140, 90, 28.5, 180]  # [idade, PA_sist, PA_diast, IMC, glicose]

# RandomOverSampler duplica EXATAMENTE:
paciente_1_copia_1 = [45, 140, 90, 28.5, 180]  # IDÃŠNTICO
paciente_1_copia_2 = [45, 140, 90, 28.5, 180]  # IDÃŠNTICO
paciente_1_copia_3 = [45, 140, 90, 28.5, 180]  # IDÃŠNTICO
                    </div>
<p style="margin-top: 15px; font-weight: 600; color: #c62828;">Problemas:</p>
<ul>
<li> <strong>Overfitting:</strong> Modelo memoriza amostras duplicadas</li>
<li> <strong>Nenhuma informaÃ§Ã£o nova:</strong> NÃ£o expande espaÃ§o de features</li>
<li> <strong>ViÃ©s artificial:</strong> Distorce cÃ¡lculos de distÃ¢ncia (KNN, SVM)</li>
<li> <strong>Baixa generalizaÃ§Ã£o:</strong> Performance no teste pode ser fraca</li>
</ul>
</div>
<h3 class="subsection-title">A SoluÃ§Ã£o: SMOTE â€” OrientaÃ§Ã£o do orientador</h3>
<div class="success-box">
<h4> O Que Ã‰ SMOTE</h4>
<p><strong>SMOTE</strong> (Chawla et al., 2002) <strong>cria amostras sintÃ©ticas</strong> da classe minoritÃ¡ria por <strong>interpolaÃ§Ã£o</strong> entre vizinhos prÃ³ximos.</p>
<p style="margin-top: 15px;"><strong>Como Funciona (Passo a Passo):</strong></p>
<ol>
<li>Para cada amostra da classe minoritÃ¡ria</li>
<li>Encontra os <strong>k vizinhos mais prÃ³ximos</strong> (geralmente k=5)</li>
<li>Seleciona <strong>aleatoriamente</strong> um desses vizinhos</li>
<li>Cria nova amostra <strong>interpolando</strong> entre os dois</li>
<li>Repete atÃ© atingir balanceamento desejado</li>
</ol>
</div>
<h3 class="subsection-title">VisualizaÃ§Ã£o: Como SMOTE Cria Amostras â€” OrientaÃ§Ã£o do orientador</h3>
<div class="visual-diagram">
<div class="diagram-title">Processo de InterpolaÃ§Ã£o do SMOTE</div>
<pre class="code-block" data-label="CÃ³digo" style="font-family: monospace; text-align: left; display: inline-block; line-height: 1.8;">
Amostra Original (x_i):        [45, 140, 90, 28.5, 180]
                                      â†“
          Encontrar 5 vizinhos mais prÃ³ximos da classe minoritÃ¡ria
                                      â†“
Vizinho escolhido (x_zi):      [47, 145, 92, 29.0, 185]
                                      â†“
           Gerar nÃºmero aleatÃ³rio Î» entre 0 e 1 â†’ Î» = 0.6
                                      â†“
                <strong>FÃ³rmula: x_novo = x_i + Î» Ã— (x_zi - x_i)</strong>
                                      â†“
Nova amostra sintÃ©tica:        [46.2, 143, 91.2, 28.8, 183]
                                   â†‘
                      NOVA, ÃšNICA E PLAUSÃVEL!
</pre>
</div>
<div class="formula">
<strong>FÃ³rmula MatemÃ¡tica do SMOTE:</strong><br/><br/>
                    x<sub>novo</sub> = x<sub>i</sub> + Î» Ã— (x<sub>zi</sub> - x<sub>i</sub>)<br/><br/>
                    onde:<br/>
                    â€¢ x<sub>i</sub> = amostra original da classe minoritÃ¡ria<br/>
                    â€¢ x<sub>zi</sub> = vizinho selecionado aleatoriamente<br/>
                    â€¢ Î» = nÃºmero aleatÃ³rio entre 0 e 1<br/>
                    â€¢ x<sub>novo</sub> = nova amostra sintÃ©tica
                </div>
<h3 class="subsection-title">ComparaÃ§Ã£o Direta: RandomOverSampler vs SMOTE â€” OrientaÃ§Ã£o do orientador</h3>
<div class="pros-cons">
<div style="background: #ffebee; border: 2px solid #f44336; padding: 20px; border-radius: 10px;">
<h4 style="color: #c62828;"> RandomOverSampler</h4>
<p><strong>MÃ©todo:</strong> DuplicaÃ§Ã£o exata</p>
<ul>
<li>Copia amostras idÃªnticas</li>
<li>Alto risco de overfitting</li>
<li>MemorizaÃ§Ã£o de padrÃµes</li>
<li>NÃ£o adiciona informaÃ§Ã£o</li>
<li>Distorce mÃ©tricas de distÃ¢ncia</li>
</ul>
<p style="margin-top: 15px; font-weight: 600;">Adequado para: Testes rÃ¡pidos, dados muito pequenos</p>
</div>
<div style="background: #e8f5e9; border: 2px solid #4CAF50; padding: 20px; border-radius: 10px;">
<h4 style="color: #2e7d32;"> SMOTE</h4>
<p><strong>MÃ©todo:</strong> InterpolaÃ§Ã£o sintÃ©tica</p>
<ul>
<li>Cria amostras Ãºnicas</li>
<li>Reduz overfitting significativamente</li>
<li>ForÃ§a aprendizado de padrÃµes gerais</li>
<li>Expande espaÃ§o de features</li>
<li>Preserva estrutura de distÃ¢ncias</li>
</ul>
<p style="margin-top: 15px; font-weight: 600;">Adequado para: ProduÃ§Ã£o, trabalhos acadÃªmicos, aplicaÃ§Ãµes reais</p>
</div>
</div>
<h3 class="subsection-title">CÃ³digo: ImplementaÃ§Ã£o de SMOTE â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 1: Importar bibliotecas</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">from</span> imblearn.over_sampling <span class="code-keyword">import</span> SMOTE
<span class="code-keyword">from</span> sklearn.model_selection <span class="code-keyword">import</span> train_test_split
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 2: Separar features e target</span>
<span class="code-comment"># ============================================================</span>
X = df.drop(<span class="code-string">'risco_hipertensao'</span>, axis=1)
y = df[<span class="code-string">'risco_hipertensao'</span>]

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 3: DivisÃ£o treino/teste (com estratificaÃ§Ã£o)</span>
<span class="code-comment"># ============================================================</span>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.25,      <span class="code-comment"># 75% treino, 25% teste</span>
    random_state=42,     <span class="code-comment"># Reprodutibilidade</span>
    stratify=y           <span class="code-comment"># MantÃ©m proporÃ§Ã£o de classes</span>
)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 4: Ver distribuiÃ§Ã£o ANTES do SMOTE</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">"="</span>*70)
<span class="code-function">print</span>(<span class="code-string">"ANÃLISE DE BALANCEAMENTO - ANTES DO SMOTE"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*70)

<span class="code-function">print</span>(<span class="code-string">f"\nDistribuiÃ§Ã£o original (treino):"</span>)
<span class="code-function">print</span>(<span class="code-function">pd.Series</span>(y_train).value_counts())

classe_0 = (y_train == 0).sum()
classe_1 = (y_train == 1).sum()
razao = classe_0 / classe_1

<span class="code-function">print</span>(<span class="code-string">f"\nClasse 0 (Sem risco): {classe_0} ({classe_0/len(y_train)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"Classe 1 (Com risco): {classe_1} ({classe_1/len(y_train)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"RazÃ£o de desbalanceamento: 1:{razao:.2f}"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 5: Aplicar SMOTE</span>
<span class="code-comment"># ============================================================</span>
smote = SMOTE(
    sampling_strategy=<span class="code-string">'auto'</span>,  <span class="code-comment"># Balanceia para 1:1</span>
    k_neighbors=5,              <span class="code-comment"># Usa 5 vizinhos (padrÃ£o)</span>
    random_state=42             <span class="code-comment"># Reprodutibilidade</span>
)

<span class="code-function">print</span>(<span class="code-string">"\nâ³ Aplicando SMOTE..."</span>)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
<span class="code-function">print</span>(<span class="code-string">" SMOTE aplicado com sucesso!"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PASSO 6: Ver distribuiÃ§Ã£o DEPOIS do SMOTE</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*70}"</span>)
<span class="code-function">print</span>(<span class="code-string">"ANÃLISE DE BALANCEAMENTO - DEPOIS DO SMOTE"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*70)

<span class="code-function">print</span>(<span class="code-string">f"\nDistribuiÃ§Ã£o apÃ³s SMOTE (treino):"</span>)
<span class="code-function">print</span>(<span class="code-function">pd.Series</span>(y_train_smote).value_counts())

classe_0_smote = (y_train_smote == 0).sum()
classe_1_smote = (y_train_smote == 1).sum()

<span class="code-function">print</span>(<span class="code-string">f"\nClasse 0: {classe_0_smote} ({classe_0_smote/len(y_train_smote)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"Classe 1: {classe_1_smote} ({classe_1_smote/len(y_train_smote)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"RazÃ£o: 1:{classe_0_smote/classe_1_smote:.2f}"</span>)

<span class="code-comment"># EstatÃ­sticas sobre amostras sintÃ©ticas</span>
amostras_originais = len(X_train)
amostras_apos_smote = len(X_train_smote)
amostras_sinteticas = amostras_apos_smote - amostras_originais

<span class="code-function">print</span>(<span class="code-string">f"\n EstatÃ­sticas:"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Amostras originais: {amostras_originais}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Amostras apÃ³s SMOTE: {amostras_apos_smote}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Amostras sintÃ©ticas criadas: {amostras_sinteticas}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   % sintÃ©ticas: {amostras_sinteticas/amostras_apos_smote*100:.1f}%"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># IMPORTANTE: SMOTE foi aplicado APENAS no TREINO!</span>
<span class="code-comment"># O conjunto de TESTE permanece INALTERADO</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*70}"</span>)
<span class="code-function">print</span>(<span class="code-string">"ï¸  IMPORTANTE:"</span>)
<span class="code-function">print</span>(<span class="code-string">"   - SMOTE aplicado APENAS no conjunto de TREINO"</span>)
<span class="code-function">print</span>(<span class="code-string">"   - Conjunto de TESTE permanece com distribuiÃ§Ã£o ORIGINAL"</span>)
<span class="code-function">print</span>(<span class="code-string">"   - Isso garante avaliaÃ§Ã£o honesta da generalizaÃ§Ã£o"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*70)
                </div>
<div class="warning-box">
<h4>ï¸ REGRA DE OURO: NUNCA Aplique SMOTE no Teste!</h4>
<p><strong>Por quÃª?</strong></p>
<ul>
<li>Conjunto de teste deve representar <strong>dados reais</strong> que o modelo verÃ¡ em produÃ§Ã£o</li>
<li>Aplicar SMOTE no teste = <strong>contaminar</strong> a avaliaÃ§Ã£o</li>
<li>Resultados serÃ£o <strong>artificialmente inflados</strong> e nÃ£o confiÃ¡veis</li>
<li>ViolaÃ§Ã£o grave das <strong>boas prÃ¡ticas</strong> de Machine Learning</li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #c62828;"> NUNCA faÃ§a: smote.fit_resample(X_test, y_test)</p>
<p style="font-weight: 600; color: #2e7d32;"> SEMPRE faÃ§a: Aplique SMOTE APENAS em X_train e y_train</p>
</div>
<h3 class="subsection-title">ParÃ¢metros Importantes do SMOTE â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>ParÃ¢metro</th>
<th>DescriÃ§Ã£o</th>
<th>Valor PadrÃ£o</th>
<th>RecomendaÃ§Ã£o para TCC</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>sampling_strategy</strong></td>
<td>Define proporÃ§Ã£o desejada apÃ³s balanceamento</td>
<td>'auto'</td>
<td><strong>'auto'</strong> (balanceia para 1:1)</td>
</tr>
<tr>
<td><strong>k_neighbors</strong></td>
<td>NÃºmero de vizinhos usados para interpolaÃ§Ã£o</td>
<td>5</td>
<td><strong>5</strong> (adequado para maioria dos casos)</td>
</tr>
<tr>
<td><strong>random_state</strong></td>
<td>Semente para reprodutibilidade</td>
<td>None</td>
<td><strong>42</strong> (garante resultados reproduzÃ­veis)</td>
</tr>
</tbody>
</table>
<div class="key-takeaway">
<h4>Pontos-Chave do SMOTE</h4>
<ul>
<li> SMOTE <strong>cria amostras sintÃ©ticas</strong> por interpolaÃ§Ã£o, nÃ£o duplicaÃ§Ã£o</li>
<li> Usa <strong>k vizinhos</strong> (padrÃ£o k=5) para criar amostras plausÃ­veis</li>
<li> <strong>Reduz overfitting</strong> significativamente vs RandomOverSampler</li>
<li> <strong>Melhoria esperada</strong> de 2-7% em Sensibilidade</li>
<li> Aplicar <strong>APENAS no treino</strong>, NUNCA no teste</li>
<li> TÃ©cnica <strong>estado-da-arte</strong> com 18.000+ citaÃ§Ãµes</li>
</ul>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" onclick="prevTab()">
                        â† Anterior
                    </button>
<button class="nav-button next" onclick="nextTab()">
                        PrÃ³ximo: ProporÃ§Ãµes de Treino â†’
                    </button>
</div>
</div>
<!-- TAB 3: PROPORÃ‡Ã•ES DE TREINO/TESTE -->
<div class="tab-content" id="tab3">
<h2 class="section-title">TÃ©cnica 2: OtimizaÃ§Ã£o das ProporÃ§Ãµes de Treino/Teste â€” OrientaÃ§Ã£o do orientador</h2>
<div class="info-box">
<h4>OrientaÃ§Ã£o desta seÃ§Ã£o</h4>
<p>Aprender a <strong>testar diferentes proporÃ§Ãµes</strong> de divisÃ£o treino/teste (60/40, 70/30, 75/25, 80/20) para encontrar o <strong>equilÃ­brio Ã³timo</strong> entre dados para treinar o modelo e dados para avaliÃ¡-lo.</p>
</div>
<h3 class="subsection-title">Por Que a ProporÃ§Ã£o Importa? â€” OrientaÃ§Ã£o do orientador</h3>
<div class="step-card">
<div class="step-number">?</div>
<div class="step-content">
<div class="step-title">O Dilema Fundamental</div>
<p>Ao dividir seus dados, vocÃª enfrenta um <strong>trade-off crÃ­tico</strong>:</p>
<ul>
<li><strong>Mais dados para TREINO</strong> (ex: 80%) â†’ Modelo aprende melhor, mas avaliaÃ§Ã£o menos confiÃ¡vel</li>
<li><strong>Mais dados para TESTE</strong> (ex: 60%) â†’ AvaliaÃ§Ã£o mais confiÃ¡vel, mas modelo aprende pior</li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #667eea;">A proporÃ§Ã£o ideal depende do tamanho total do seu dataset!</p>
</div>
</div>
<h3 class="subsection-title">ProporÃ§Ãµes Comuns e Quando Usar â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>ProporÃ§Ã£o</th>
<th>Treino</th>
<th>Teste</th>
<th>Quando Usar</th>
<th>Vantagens</th>
<th>Desvantagens</th>
</tr>
</thead>
<tbody>
<tr style="background: #fff9e6;">
<td><strong>60/40</strong></td>
<td>60%</td>
<td>40%</td>
<td>Datasets muito pequenos (&lt;500)</td>
<td>
                                â€¢ Teste mais confiÃ¡vel<br/>
                                â€¢ Mais dados p/ avaliaÃ§Ã£o
                            </td>
<td>
                                â€¢ Pouco treino<br/>
                                â€¢ Modelo pode nÃ£o aprender bem
                            </td>
</tr>
<tr>
<td><strong>70/30</strong></td>
<td>70%</td>
<td>30%</td>
<td>Datasets pequenos (500-2000)</td>
<td>
                                â€¢ Bom balanÃ§o<br/>
                                â€¢ Teste ainda robusto
                            </td>
<td>
                                â€¢ Pode ser subÃ³timo
                            </td>
</tr>
<tr style="background: #e8f5e9;">
<td><strong>75/25</strong></td>
<td>75%</td>
<td>25%</td>
<td><strong>Mais comum (mÃ©dio, 2000-10000)</strong></td>
<td>
                                â€¢ Balanceamento clÃ¡ssico<br/>
                                â€¢ Amplamente aceito<br/>
                                â€¢ Bom para TCC
                            </td>
<td>
                                â€¢ Pode nÃ£o ser Ã³timo p/ extremos
                            </td>
</tr>
<tr>
<td><strong>80/20</strong></td>
<td>80%</td>
<td>20%</td>
<td>Datasets grandes (&gt;10000)</td>
<td>
                                â€¢ Mais treino<br/>
                                â€¢ Modelo aprende melhor
                            </td>
<td>
                                â€¢ Teste menos robusto<br/>
                                â€¢ Pode ser otimista
                            </td>
</tr>
<tr style="background: #ffebee;">
<td><strong>90/10</strong></td>
<td>90%</td>
<td>10%</td>
<td>Datasets muito grandes (&gt;100000)</td>
<td>
                                â€¢ MÃ¡ximo aprendizado
                            </td>
<td>
                                â€¢ Teste pequeno<br/>
                                â€¢ Alta variÃ¢ncia<br/>
                                â€¢ NÃ£o recomendado p/ TCC
                            </td>
</tr>
</tbody>
</table>
<div class="critical-box">
<h4> Problema do Seu TCC Atual</h4>
<p>O TCC usa <strong>apenas uma proporÃ§Ã£o</strong> (75/25) sem justificativa ou comparaÃ§Ã£o.</p>
<p><strong>QuestÃµes nÃ£o respondidas:</strong></p>
<ul>
<li>75/25 Ã© realmente a melhor proporÃ§Ã£o para este dataset?</li>
<li>Outras proporÃ§Ãµes dariam melhores resultados?</li>
<li>Como justificar esta escolha perante a banca?</li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #c62828;">SoluÃ§Ã£o: Testar sistematicamente mÃºltiplas proporÃ§Ãµes e escolher a melhor!</p>
</div>
<h3 class="subsection-title">CÃ³digo: ComparaÃ§Ã£o de ProporÃ§Ãµes â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># COMPARAÃ‡ÃƒO SISTEMÃTICA DE PROPORÃ‡Ã•ES TREINO/TESTE</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">from</span> sklearn.model_selection <span class="code-keyword">import</span> train_test_split
<span class="code-keyword">from</span> sklearn.ensemble <span class="code-keyword">import</span> RandomForestClassifier
<span class="code-keyword">from</span> sklearn.metrics <span class="code-keyword">import</span> (
    recall_score, precision_score, f1_score, 
    fbeta_score, roc_auc_score
)
<span class="code-keyword">from</span> imblearn.over_sampling <span class="code-keyword">import</span> SMOTE
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt

<span class="code-comment"># Definir proporÃ§Ãµes para testar</span>
proporcoes = {
    <span class="code-string">'60/40'</span>: 0.40,
    <span class="code-string">'70/30'</span>: 0.30,
    <span class="code-string">'75/25'</span>: 0.25,  <span class="code-comment"># ATUAL no TCC</span>
<span class="code-string">'80/20'</span>: 0.20
}

resultados = []

<span class="code-function">print</span>(<span class="code-string">"="</span>*80)
<span class="code-function">print</span>(<span class="code-string">"ANÃLISE DE DIFERENTES PROPORÃ‡Ã•ES TREINO/TESTE"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

<span class="code-keyword">for</span> nome, test_size <span class="code-keyword">in</span> proporcoes.items():
    <span class="code-function">print</span>(<span class="code-string">f"\n{'â”€'*80}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" Testando proporÃ§Ã£o: {nome}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*80}"</span>)
    
    <span class="code-comment"># 1. Dividir dados</span>
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=42,
        stratify=y
    )
    
    <span class="code-function">print</span>(<span class="code-string">f"   Treino: {len(X_train)} amostras ({(1-test_size)*100:.0f}%)"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   Teste:  {len(X_test)} amostras ({test_size*100:.0f}%)"</span>)
    
    <span class="code-comment"># 2. Aplicar SMOTE (apenas no treino)</span>
    smote = SMOTE(random_state=42, k_neighbors=5)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
    
    <span class="code-comment"># 3. Treinar modelo</span>
    modelo = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight=<span class="code-string">'balanced'</span> <span class="code-comment"># Peso adicional para classe minoritÃ¡ria</span>
    )
    modelo.fit(X_train_balanced, y_train_balanced)
    
    <span class="code-comment"># 4. Fazer prediÃ§Ãµes</span>
    y_pred = modelo.predict(X_test)
    y_proba = modelo.predict_proba(X_test)[:, 1]
    
    <span class="code-comment"># 5. Calcular mÃ©tricas</span>
    sensibilidade = recall_score(y_test, y_pred)
    precisao = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    f2 = fbeta_score(y_test, y_pred, beta=2)
    roc_auc = roc_auc_score(y_test, y_proba)
    
    <span class="code-comment"># Falsos negativos (mais importante para hipertensÃ£o)</span>
    fn = ((y_test == 1) &amp; (y_pred == 0)).sum()
    
    <span class="code-function">print</span>(<span class="code-string">f"\n    Resultados:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Sensibilidade:     {sensibilidade:.4f} ({sensibilidade*100:.2f}%)"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      PrecisÃ£o:          {precisao:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      F1-Score:          {f1:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      F2-Score:          {f2:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      ROC-AUC:           {roc_auc:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Falsos Negativos:  {fn}"</span>)
    
    <span class="code-comment"># Armazenar resultados</span>
    resultados.append({
        <span class="code-string">'ProporÃ§Ã£o'</span>: nome,
        <span class="code-string">'Test_Size'</span>: test_size,
        <span class="code-string">'N_Treino'</span>: len(X_train),
        <span class="code-string">'N_Teste'</span>: len(X_test),
        <span class="code-string">'Sensibilidade'</span>: sensibilidade,
        <span class="code-string">'PrecisÃ£o'</span>: precisao,
        <span class="code-string">'F1-Score'</span>: f1,
        <span class="code-string">'F2-Score'</span>: f2,
        <span class="code-string">'ROC-AUC'</span>: roc_auc,
        <span class="code-string">'FN'</span>: fn
    })

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># ANÃLISE E COMPARAÃ‡ÃƒO DOS RESULTADOS</span>
<span class="code-comment"># ============================================================</span>
df_resultados = pd.DataFrame(resultados)

<span class="code-function">print</span>(<span class="code-string">f"\n{'='*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">" RESUMO COMPARATIVO"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)
<span class="code-function">print</span>(df_resultados.to_string(index=<span class="code-keyword">False</span>))

<span class="code-comment"># Identificar melhor proporÃ§Ã£o (por F2-Score - prioriza Sensibilidade)</span>
melhor_idx = df_resultados[<span class="code-string">'F2-Score'</span>].idxmax()
melhor = df_resultados.iloc[melhor_idx]

<span class="code-function">print</span>(<span class="code-string">f"\n{'='*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">" MELHOR PROPORÃ‡ÃƒO (baseada em F2-Score)"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)
<span class="code-function">print</span>(<span class="code-string">f"\n   ProporÃ§Ã£o:         {melhor['ProporÃ§Ã£o']}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   F2-Score:          {melhor['F2-Score']:.4f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Sensibilidade:     {melhor['Sensibilidade']:.4f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Falsos Negativos:  {int(melhor['FN'])}"</span>)

<span class="code-comment"># Comparar com 75/25 (atual do TCC)</span>
atual = df_resultados[df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>] == <span class="code-string">'75/25'</span>].iloc[0]

<span class="code-keyword">if</span> melhor[<span class="code-string">'ProporÃ§Ã£o'</span>] != <span class="code-string">'75/25'</span>:
    <span class="code-function">print</span>(<span class="code-string">f"\nï¸  ATENÃ‡ÃƒO: ProporÃ§Ã£o 75/25 (atual) NÃƒO Ã© a melhor!"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"\n   Ganho ao mudar para {melhor['ProporÃ§Ã£o']}:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Î”F2-Score:         {(melhor['F2-Score'] - atual['F2-Score']):.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Î”Sensibilidade:    {(melhor['Sensibilidade'] - atual['Sensibilidade']):.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Î”Falsos Negativos: {int(melhor['FN'] - atual['FN'])}"</span>)
<span class="code-keyword">else</span>:
    <span class="code-function">print</span>(<span class="code-string">f"\n ProporÃ§Ã£o 75/25 (atual) Ã© a melhor opÃ§Ã£o!"</span>)

<span class="code-comment"># Salvar resultados</span>
df_resultados.to_csv(<span class="code-string">'comparacao_proporcoes.csv'</span>, index=<span class="code-keyword">False</span>)
<span class="code-function">print</span>(<span class="code-string">f"\n Resultados salvos em: comparacao_proporcoes.csv"</span>)
                </div>
<h3 class="subsection-title">VisualizaÃ§Ã£o dos Resultados â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># VISUALIZAÃ‡ÃƒO: ComparaÃ§Ã£o de MÃ©tricas por ProporÃ§Ã£o</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

<span class="code-comment"># Plot 1: F2-Score por proporÃ§Ã£o</span>
ax1 = axes[0, 0]
colors = [<span class="code-string">'#ff7043'</span> <span class="code-keyword">if</span> p == <span class="code-string">'75/25'</span> <span class="code-keyword">else</span> <span class="code-string">'#66bb6a'</span>
<span class="code-keyword">for</span> p <span class="code-keyword">in</span> df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>]]
ax1.bar(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'F2-Score'</span>], color=colors)
ax1.set_title(<span class="code-string">'F2-Score por ProporÃ§Ã£o\n(MÃ©trica Principal)'</span>, 
             fontsize=13, fontweight=<span class="code-string">'bold'</span>)
ax1.set_ylabel(<span class="code-string">'F2-Score'</span>, fontweight=<span class="code-string">'bold'</span>)
ax1.set_xlabel(<span class="code-string">'ProporÃ§Ã£o Treino/Teste'</span>, fontweight=<span class="code-string">'bold'</span>)
ax1.grid(axis=<span class="code-string">'y'</span>, alpha=0.3)

<span class="code-comment"># Destacar melhor</span>
melhor_prop = df_resultados.loc[df_resultados[<span class="code-string">'F2-Score'</span>].idxmax(), <span class="code-string">'ProporÃ§Ã£o'</span>]
melhor_f2 = df_resultados[<span class="code-string">'F2-Score'</span>].max()
ax1.axhline(melhor_f2, color=<span class="code-string">'red'</span>, linestyle=<span class="code-string">'--'</span>, alpha=0.5, label=<span class="code-string">'Melhor'</span>)
ax1.legend()

<span class="code-comment"># Plot 2: Sensibilidade por proporÃ§Ã£o</span>
ax2 = axes[0, 1]
ax2.bar(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'Sensibilidade'</span>], color=colors)
ax2.set_title(<span class="code-string">'Sensibilidade (Recall) por ProporÃ§Ã£o\n(Detectar Casos Positivos)'</span>, 
             fontsize=13, fontweight=<span class="code-string">'bold'</span>)
ax2.set_ylabel(<span class="code-string">'Sensibilidade'</span>, fontweight=<span class="code-string">'bold'</span>)
ax2.set_xlabel(<span class="code-string">'ProporÃ§Ã£o Treino/Teste'</span>, fontweight=<span class="code-string">'bold'</span>)
ax2.grid(axis=<span class="code-string">'y'</span>, alpha=0.3)

<span class="code-comment"># Linha de meta (90%)</span>
ax2.axhline(0.90, color=<span class="code-string">'green'</span>, linestyle=<span class="code-string">'--'</span>, alpha=0.5, label=<span class="code-string">'Meta (90%)'</span>)
ax2.legend()

<span class="code-comment"># Plot 3: Falsos Negativos por proporÃ§Ã£o</span>
ax3 = axes[1, 0]
ax3.bar(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'FN'</span>], color=colors)
ax3.set_title(<span class="code-string">'Falsos Negativos por ProporÃ§Ã£o\n(Menor Ã© Melhor)'</span>, 
             fontsize=13, fontweight=<span class="code-string">'bold'</span>)
ax3.set_ylabel(<span class="code-string">'NÃºmero de Falsos Negativos'</span>, fontweight=<span class="code-string">'bold'</span>)
ax3.set_xlabel(<span class="code-string">'ProporÃ§Ã£o Treino/Teste'</span>, fontweight=<span class="code-string">'bold'</span>)
ax3.grid(axis=<span class="code-string">'y'</span>, alpha=0.3)

<span class="code-comment"># Plot 4: MÃºltiplas mÃ©tricas (linhas)</span>
ax4 = axes[1, 1]
ax4.plot(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'Sensibilidade'</span>], 
        marker=<span class="code-string">'o'</span>, linewidth=2, label=<span class="code-string">'Sensibilidade'</span>, color=<span class="code-string">'#4CAF50'</span>)
ax4.plot(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'PrecisÃ£o'</span>], 
        marker=<span class="code-string">'s'</span>, linewidth=2, label=<span class="code-string">'PrecisÃ£o'</span>, color=<span class="code-string">'#2196F3'</span>)
ax4.plot(df_resultados[<span class="code-string">'ProporÃ§Ã£o'</span>], df_resultados[<span class="code-string">'F2-Score'</span>], 
        marker=<span class="code-string">'^'</span>, linewidth=2, label=<span class="code-string">'F2-Score'</span>, color=<span class="code-string">'#9C27B0'</span>)
ax4.set_title(<span class="code-string">'ComparaÃ§Ã£o de MÃºltiplas MÃ©tricas'</span>, fontsize=13, fontweight=<span class="code-string">'bold'</span>)
ax4.set_ylabel(<span class="code-string">'Valor da MÃ©trica'</span>, fontweight=<span class="code-string">'bold'</span>)
ax4.set_xlabel(<span class="code-string">'ProporÃ§Ã£o Treino/Teste'</span>, fontweight=<span class="code-string">'bold'</span>)
ax4.legend()
ax4.grid(alpha=0.3)

plt.suptitle(<span class="code-string">'AnÃ¡lise Comparativa de ProporÃ§Ãµes Treino/Teste\nPrediÃ§Ã£o de HipertensÃ£o'</span>,
            fontsize=15, fontweight=<span class="code-string">'bold'</span>, y=0.995)
plt.tight_layout()
plt.savefig(<span class="code-string">'comparacao_proporcoes.png'</span>, dpi=300, bbox_inches=<span class="code-string">'tight'</span>)
plt.show()

<span class="code-function">print</span>(<span class="code-string">"\n VisualizaÃ§Ãµes salvas em: comparacao_proporcoes.png"</span>)
                </div>
<h3 class="subsection-title">Como Interpretar os Resultados â€” OrientaÃ§Ã£o do orientador</h3>
<div class="success-box">
<h4> Diretrizes para Escolher a Melhor ProporÃ§Ã£o</h4>
<p><strong>Para o problema de prediÃ§Ã£o de hipertensÃ£o, priorize:</strong></p>
<ol>
<li><strong>F2-Score mais alto</strong> - mÃ©trica principal que prioriza Sensibilidade</li>
<li><strong>Sensibilidade â‰¥ 90%</strong> - detectar pelo menos 90% dos casos de risco</li>
<li><strong>Menor nÃºmero de Falsos Negativos</strong> - minimizar casos nÃ£o detectados</li>
<li><strong>Tamanho de teste adequado</strong> - pelo menos 200-300 amostras para avaliaÃ§Ã£o confiÃ¡vel</li>
</ol>
</div>
<div class="warning-box">
<h4>ï¸ Cuidados na InterpretaÃ§Ã£o</h4>
<ul>
<li>DiferenÃ§as <strong>&lt;1%</strong> entre proporÃ§Ãµes geralmente nÃ£o sÃ£o significativas</li>
<li>Considere o <strong>contexto</strong>: mais treino = melhor aprendizado, mais teste = avaliaÃ§Ã£o mais confiÃ¡vel</li>
<li>Para TCC, proporÃ§Ãµes tradicionais (70/30 ou 75/25) sÃ£o mais aceitas pela banca</li>
<li>Se usar proporÃ§Ã£o nÃ£o-convencional, <strong>justifique</strong> com dados desta anÃ¡lise</li>
</ul>
</div>
<div class="key-takeaway">
<h4>Pontos-Chave sobre ProporÃ§Ãµes</h4>
<ul>
<li> NÃ£o existe proporÃ§Ã£o "perfeita" - depende do <strong>tamanho do dataset</strong></li>
<li> <strong>Testar mÃºltiplas proporÃ§Ãµes</strong> demonstra rigor metodolÃ³gico</li>
<li> Para TCC com ~3000 amostras, <strong>70/30 ou 75/25</strong> sÃ£o geralmente ideais</li>
<li> Priorize <strong>F2-Score e Sensibilidade</strong> na escolha</li>
<li> Documente a <strong>justificativa da escolha</strong> no TCC</li>
<li> Esta anÃ¡lise fortalece a <strong>argumentaÃ§Ã£o perante a banca</strong></li>
</ul>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" onclick="prevTab()">
                        â† Anterior
                    </button>
<button class="nav-button next" onclick="nextTab()">
                        PrÃ³ximo: K-Fold â†’
                    </button>
</div>
</div>
<!-- TAB 4: K-FOLD -->
<div class="tab-content" id="tab4">
<h2 class="section-title">TÃ©cnica 3: K-Fold Cross-Validation â€” OrientaÃ§Ã£o do orientador</h2>
<div class="info-box">
<h4>OrientaÃ§Ã£o desta seÃ§Ã£o</h4>
<p>Aprender a usar <strong>K-Fold Cross-Validation</strong> para obter avaliaÃ§Ã£o mais <strong>robusta e confiÃ¡vel</strong> do modelo, ao invÃ©s de depender de uma Ãºnica divisÃ£o treino/teste.</p>
</div>
<h3 class="subsection-title">O Problema da DivisÃ£o Ãšnica â€” OrientaÃ§Ã£o do orientador</h3>
<div class="critical-box">
<h4> LimitaÃ§Ã£o da Abordagem Atual no TCC</h4>
<p><strong>Problema:</strong> Uma Ãºnica divisÃ£o treino/teste pode dar resultados <strong>enviesados ou instÃ¡veis</strong>.</p>
<p style="margin-top: 15px;"><strong>Por quÃª?</strong></p>
<ul>
<li><strong>Sorte na divisÃ£o:</strong> Pode ser que conjunto de teste seja "fÃ¡cil" ou "difÃ­cil" por acaso</li>
<li><strong>Outliers no teste:</strong> Alguns casos atÃ­picos podem distorcer mÃ©tricas</li>
<li><strong>Baixa confianÃ§a estatÃ­stica:</strong> Resultados nÃ£o sÃ£o reproduzÃ­veis</li>
<li><strong>Variabilidade alta:</strong> Executar de novo pode dar resultados bem diferentes</li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #c62828;">
                        Exemplo: Modelo pode ter 92% de Sensibilidade numa divisÃ£o, mas 87% em outra!
                    </p>
</div>
<h3 class="subsection-title">A SoluÃ§Ã£o: K-Fold Cross-Validation â€” OrientaÃ§Ã£o do orientador</h3>
<div class="success-box">
<h4> O Que Ã‰ K-Fold</h4>
<p><strong>Ideia Central:</strong> Em vez de uma divisÃ£o, fazer <strong>K divisÃµes diferentes</strong> e calcular a <strong>mÃ©dia</strong> das mÃ©tricas.</p>
<p style="margin-top: 15px;"><strong>Como Funciona (K=5):</strong></p>
<ol>
<li>Dividir dados em <strong>5 partes iguais</strong> (folds)</li>
<li><strong>IteraÃ§Ã£o 1:</strong> Usar fold 1 como teste, folds 2-5 como treino</li>
<li><strong>IteraÃ§Ã£o 2:</strong> Usar fold 2 como teste, folds 1,3,4,5 como treino</li>
<li><strong>IteraÃ§Ã£o 3:</strong> Usar fold 3 como teste, demais como treino</li>
<li><strong>IteraÃ§Ã£o 4:</strong> Usar fold 4 como teste, demais como treino</li>
<li><strong>IteraÃ§Ã£o 5:</strong> Usar fold 5 como teste, demais como treino</li>
<li><strong>Resultado Final:</strong> MÃ©dia das 5 iteraÃ§Ãµes Â± desvio padrÃ£o</li>
</ol>
</div>
<h3 class="subsection-title">VisualizaÃ§Ã£o: Como K-Fold Funciona â€” OrientaÃ§Ã£o do orientador</h3>
<div class="visual-diagram">
<div class="diagram-title">K-Fold Cross-Validation com K=5</div>
<pre class="code-block" data-label="CÃ³digo" style="font-family: monospace; text-align: left; display: inline-block; line-height: 2;">
<strong>Dataset Completo:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Fold 1 â”‚  Fold 2 â”‚  Fold 3 â”‚  Fold 4 â”‚  Fold 5 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

<strong>IteraÃ§Ã£o 1:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TESTE  â”‚           TREINO                    â”‚ â†’ MÃ©tricasâ‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

<strong>IteraÃ§Ã£o 2:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TREINO â”‚  TESTE  â”‚        TREINO           â”‚ â†’ MÃ©tricasâ‚‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

<strong>IteraÃ§Ã£o 3:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      TREINO       â”‚  TESTE  â”‚    TREINO     â”‚ â†’ MÃ©tricasâ‚ƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

<strong>IteraÃ§Ã£o 4:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚          TREINO             â”‚  TESTE  â”‚ TR. â”‚ â†’ MÃ©tricasâ‚„
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

<strong>IteraÃ§Ã£o 5:</strong>
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚              TREINO                   â”‚ TESTâ”‚ â†’ MÃ©tricasâ‚…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

<strong>Resultado Final:</strong>
Sensibilidade = mÃ©dia(Mâ‚, Mâ‚‚, Mâ‚ƒ, Mâ‚„, Mâ‚…) Â± desvio_padrÃ£o
F2-Score      = mÃ©dia(Mâ‚, Mâ‚‚, Mâ‚ƒ, Mâ‚„, Mâ‚…) Â± desvio_padrÃ£o
</pre>
</div>
<h3 class="subsection-title">Vantagens do K-Fold â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>Aspecto</th>
<th>DivisÃ£o Ãšnica (Atual)</th>
<th>K-Fold (Proposto)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NÃºmero de AvaliaÃ§Ãµes</strong></td>
<td>1 Ãºnica divisÃ£o</td>
<td style="background: #e8f5e9;">K divisÃµes (ex: 5 ou 10)</td>
</tr>
<tr>
<td><strong>Confiabilidade</strong></td>
<td>Baixa - pode ter sorte/azar</td>
<td style="background: #e8f5e9;">Alta - mÃ©dia de mÃºltiplas avaliaÃ§Ãµes</td>
</tr>
<tr>
<td><strong>Uso dos Dados</strong></td>
<td>75% treino, 25% nunca usado</td>
<td style="background: #e8f5e9;">100% dos dados usados (em momentos diferentes)</td>
</tr>
<tr>
<td><strong>Variabilidade</strong></td>
<td>Alta - resultados instÃ¡veis</td>
<td style="background: #e8f5e9;">Baixa - mÃ©dia estabiliza resultados</td>
</tr>
<tr>
<td><strong>Intervalo de ConfianÃ§a</strong></td>
<td>NÃ£o disponÃ­vel</td>
<td style="background: #e8f5e9;">Sim - mÃ©dia Â± desvio padrÃ£o</td>
</tr>
<tr>
<td><strong>Rigor CientÃ­fico</strong></td>
<td>BÃ¡sico</td>
<td style="background: #e8f5e9;">AvanÃ§ado - aceito em publicaÃ§Ãµes</td>
</tr>
<tr>
<td><strong>Tempo de ExecuÃ§Ã£o</strong></td>
<td>RÃ¡pido</td>
<td style="background: #fff3cd;">K vezes mais lento</td>
</tr>
</tbody>
</table>
<h3 class="subsection-title">Escolhendo o Valor de K â€” OrientaÃ§Ã£o do orientador</h3>
<div class="step-card">
<div class="step-number">5</div>
<div class="step-content">
<div class="step-title">K = 5 (Cinco Folds)</div>
<ul>
<li><strong>Mais comum</strong> em prÃ¡tica</li>
<li>Bom balanÃ§o entre tempo e confiabilidade</li>
<li>Cada fold tem 20% dos dados</li>
<li>Treino usa 80% dos dados em cada iteraÃ§Ã£o</li>
</ul>
<p style="margin-top: 10px; font-weight: 600; color: #2e7d32;"> Recomendado para TCC com ~3000 amostras</p>
</div>
</div>
<div class="step-card">
<div class="step-number">10</div>
<div class="step-content">
<div class="step-title">K = 10 (Dez Folds)</div>
<ul>
<li>Mais rigoroso</li>
<li>Cada fold tem 10% dos dados</li>
<li>Treino usa 90% dos dados em cada iteraÃ§Ã£o</li>
<li>Mais prÃ³ximo de "leave-one-out"</li>
</ul>
<p style="margin-top: 10px; font-weight: 600; color: #1976d2;"> Melhor confiabilidade, mas 2x mais lento que K=5</p>
</div>
</div>
<div class="step-card">
<div class="step-number">3</div>
<div class="step-content">
<div class="step-title">K = 3 (TrÃªs Folds)</div>
<ul>
<li>Mais rÃ¡pido</li>
<li>Cada fold tem 33% dos dados</li>
<li>Menor confiabilidade estatÃ­stica</li>
</ul>
<p style="margin-top: 10px; font-weight: 600; color: #ff9800;"> Use apenas se tempo de execuÃ§Ã£o for crÃ­tico</p>
</div>
</div>
<h3 class="subsection-title">CÃ³digo: ImplementaÃ§Ã£o de K-Fold â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># K-FOLD CROSS-VALIDATION COMPLETO</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">from</span> sklearn.model_selection <span class="code-keyword">import</span> KFold
<span class="code-keyword">from</span> sklearn.ensemble <span class="code-keyword">import</span> RandomForestClassifier
<span class="code-keyword">from</span> sklearn.metrics <span class="code-keyword">import</span> (
    recall_score, precision_score, fbeta_score, 
    roc_auc_score, confusion_matrix
)
<span class="code-keyword">from</span> imblearn.over_sampling <span class="code-keyword">import</span> SMOTE
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># CONFIGURAÃ‡ÃƒO</span>
<span class="code-comment"># ============================================================</span>
K = 5  <span class="code-comment"># NÃºmero de folds</span>
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)
<span class="code-function">print</span>(<span class="code-string">f"K-FOLD CROSS-VALIDATION (K={K})"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

<span class="code-comment"># Configurar K-Fold</span>
kfold = KFold(
    n_splits=K,
    shuffle=<span class="code-keyword">True</span>,      <span class="code-comment"># Embaralhar antes de dividir</span>
    random_state=42    <span class="code-comment"># Reprodutibilidade</span>
)

<span class="code-comment"># Listas para armazenar mÃ©tricas de cada fold</span>
metricas_por_fold = {
    <span class="code-string">'sensibilidade'</span>: [],
    <span class="code-string">'precisao'</span>: [],
    <span class="code-string">'f2_score'</span>: [],
    <span class="code-string">'roc_auc'</span>: [],
    <span class="code-string">'fn'</span>: [],  <span class="code-comment"># Falsos negativos</span>
<span class="code-string">'fp'</span>: []   <span class="code-comment"># Falsos positivos</span>
}

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># EXECUTAR K-FOLD</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">for</span> fold, (train_idx, test_idx) <span class="code-keyword">in</span> <span class="code-function">enumerate</span>(kfold.split(X), 1):
    <span class="code-function">print</span>(<span class="code-string">f"\n{'â”€'*80}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" FOLD {fold}/{K}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*80}"</span>)
    
    <span class="code-comment"># 1. Dividir dados para este fold</span>
    X_train_fold = X.iloc[train_idx]
    X_test_fold = X.iloc[test_idx]
    y_train_fold = y.iloc[train_idx]
    y_test_fold = y.iloc[test_idx]
    
    <span class="code-function">print</span>(<span class="code-string">f"   Treino: {len(X_train_fold)} amostras"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   Teste:  {len(X_test_fold)} amostras"</span>)
    
    <span class="code-comment"># 2. Aplicar SMOTE (apenas no treino deste fold)</span>
    smote = SMOTE(random_state=42, k_neighbors=5)
    X_train_balanced, y_train_balanced = smote.fit_resample(
        X_train_fold, y_train_fold
    )
    
    <span class="code-function">print</span>(<span class="code-string">f"   ApÃ³s SMOTE: {len(X_train_balanced)} amostras"</span>)
    
    <span class="code-comment"># 3. Treinar modelo</span>
    modelo = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight=<span class="code-string">'balanced'</span>
    )
    modelo.fit(X_train_balanced, y_train_balanced)
    
    <span class="code-comment"># 4. Fazer prediÃ§Ãµes</span>
    y_pred = modelo.predict(X_test_fold)
    y_proba = modelo.predict_proba(X_test_fold)[:, 1]
    
    <span class="code-comment"># 5. Calcular mÃ©tricas</span>
    sensibilidade = recall_score(y_test_fold, y_pred)
    precisao = precision_score(y_test_fold, y_pred)
    f2 = fbeta_score(y_test_fold, y_pred, beta=2)
    roc_auc = roc_auc_score(y_test_fold, y_proba)
    
    <span class="code-comment"># Matriz de confusÃ£o</span>
    cm = confusion_matrix(y_test_fold, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    <span class="code-comment"># Armazenar mÃ©tricas</span>
    metricas_por_fold[<span class="code-string">'sensibilidade'</span>].append(sensibilidade)
    metricas_por_fold[<span class="code-string">'precisao'</span>].append(precisao)
    metricas_por_fold[<span class="code-string">'f2_score'</span>].append(f2)
    metricas_por_fold[<span class="code-string">'roc_auc'</span>].append(roc_auc)
    metricas_por_fold[<span class="code-string">'fn'</span>].append(fn)
    metricas_por_fold[<span class="code-string">'fp'</span>].append(fp)
    
    <span class="code-comment"># Mostrar resultados deste fold</span>
<span class="code-function">print</span>(<span class="code-string">f"\n    Resultados Fold {fold}:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Sensibilidade: {sensibilidade:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      PrecisÃ£o:      {precisao:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      F2-Score:      {f2:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      ROC-AUC:       {roc_auc:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      FN: {fn}  |  FP: {fp}"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># RESULTADOS FINAIS (MÃ‰DIA Â± DESVIO PADRÃƒO)</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">" RESULTADOS FINAIS (K-FOLD)"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

<span class="code-keyword">for</span> metrica, valores <span class="code-keyword">in</span> metricas_por_fold.items():
    media = np.mean(valores)
    std = np.std(valores)
    
    <span class="code-keyword">if</span> metrica <span class="code-keyword">in</span> [<span class="code-string">'fn'</span>, <span class="code-string">'fp'</span>]:
        <span class="code-function">print</span>(<span class="code-string">f"\n{metrica.upper()}:"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"   MÃ©dia:  {media:.1f} Â± {std:.1f}"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"   Min: {min(valores)}  |  Max: {max(valores)}"</span>)
    <span class="code-keyword">else</span>:
        <span class="code-function">print</span>(<span class="code-string">f"\n{metrica.upper().replace('_', '-')}:"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"   MÃ©dia:  {media:.4f} Â± {std:.4f}"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"   Min: {min(valores):.4f}  |  Max: {max(valores):.4f}"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># ANÃLISE ESTATÃSTICA</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">" ANÃLISE ESTATÃSTICA"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

sens_media = np.mean(metricas_por_fold[<span class="code-string">'sensibilidade'</span>])
sens_std = np.std(metricas_por_fold[<span class="code-string">'sensibilidade'</span>])

<span class="code-comment"># Intervalo de confianÃ§a (95%)</span>
<span class="code-comment"># IC = mÃ©dia Â± 1.96 * (desvio / sqrt(n))</span>
ic_lower = sens_media - 1.96 * (sens_std / np.sqrt(K))
ic_upper = sens_media + 1.96 * (sens_std / np.sqrt(K))

<span class="code-function">print</span>(<span class="code-string">f"\nSENSIBILIDADE (MÃ©trica Principal):"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   MÃ©dia:              {sens_media:.4f} ({sens_media*100:.2f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Desvio PadrÃ£o:      {sens_std:.4f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   IC 95%:             [{ic_lower:.4f}, {ic_upper:.4f}]"</span>)

<span class="code-keyword">if</span> sens_media &gt;= 0.90:
    <span class="code-function">print</span>(<span class="code-string">f"\n META ATINGIDA: Sensibilidade â‰¥ 90%"</span>)
<span class="code-keyword">else</span>:
    <span class="code-function">print</span>(<span class="code-string">f"\nï¸  Sensibilidade abaixo da meta de 90%"</span>)

<span class="code-comment"># Salvar resultados</span>
df_resultados = pd.DataFrame(metricas_por_fold)
df_resultados[<span class="code-string">'fold'</span>] = <span class="code-function">range</span>(1, K+1)
df_resultados.to_csv(<span class="code-string">f'kfold_k{K}_resultados.csv'</span>, index=<span class="code-keyword">False</span>)

<span class="code-function">print</span>(<span class="code-string">f"\n Resultados salvos em: kfold_k{K}_resultados.csv"</span>)
                </div>
<div class="key-takeaway">
<h4>Pontos-Chave do K-Fold</h4>
<ul>
<li> K-Fold fornece <strong>mÃ©dia Â± desvio padrÃ£o</strong> das mÃ©tricas (mais confiÃ¡vel)</li>
<li> Usa <strong>100% dos dados</strong> (em momentos diferentes)</li>
<li> <strong>K=5 ou K=10</strong> sÃ£o os valores mais comuns</li>
<li> Aplicar <strong>SMOTE em cada fold</strong> separadamente</li>
<li> Resulta em <strong>K modelos treinados</strong> (usar mÃ©dia para avaliaÃ§Ã£o)</li>
<li> <strong>Muito mais rigoroso</strong> que divisÃ£o Ãºnica</li>
<li> Tempo: <strong>K vezes mais lento</strong> que divisÃ£o simples</li>
</ul>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" onclick="prevTab()">
                        â† Anterior
                    </button>
<button class="nav-button next" onclick="nextTab()">
                        PrÃ³ximo: ValidaÃ§Ã£o Cruzada Estratificada â†’
                    </button>
</div>
</div>
<!-- TAB 5: VALIDAÃ‡ÃƒO CRUZADA ESTRATIFICADA -->
<div class="tab-content" id="tab5">
<h2 class="section-title">TÃ©cnica 4: ValidaÃ§Ã£o Cruzada Estratificada â€” OrientaÃ§Ã£o do orientador</h2>
<div class="info-box">
<h4>OrientaÃ§Ã£o desta seÃ§Ã£o</h4>
<p>Aprender a usar <strong>Stratified K-Fold</strong>, uma variaÃ§Ã£o do K-Fold que <strong>garante que cada fold mantenha a proporÃ§Ã£o original de classes</strong>, essencial para dados desbalanceados como o problema de hipertensÃ£o.</p>
</div>
<h3 class="subsection-title">O Problema do K-Fold Simples com Dados Desbalanceados â€” OrientaÃ§Ã£o do orientador</h3>
<div class="critical-box">
<h4> Risco com K-Fold PadrÃ£o</h4>
<p><strong>CenÃ¡rio:</strong> Dataset com 70% classe 0 (sem risco) e 30% classe 1 (com risco)</p>
<p style="margin-top: 15px;"><strong>Problema:</strong> K-Fold padrÃ£o pode criar folds desbalanceados por <strong>azar na divisÃ£o</strong>:</p>
<ul>
<li>Fold 1: 65% classe 0, 35% classe 1 (mais casos positivos)</li>
<li>Fold 2: 75% classe 0, 25% classe 1 (menos casos positivos)</li>
<li>Fold 3: 68% classe 0, 32% classe 1</li>
<li>...</li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #c62828;">
                        ConsequÃªncia: MÃ©tricas inconsistentes entre folds, resultados nÃ£o confiÃ¡veis!
                    </p>
</div>
<h3 class="subsection-title">A SoluÃ§Ã£o: Stratified K-Fold â€” OrientaÃ§Ã£o do orientador</h3>
<div class="success-box">
<h4> O Que Ã‰ Stratified K-Fold</h4>
<p><strong>DiferenÃ§a:</strong> <strong>Garante que cada fold mantenha a mesma proporÃ§Ã£o de classes</strong> do dataset original.</p>
<p style="margin-top: 15px;"><strong>Exemplo:</strong> Se dataset original tem 70/30, todos os folds terÃ£o ~70/30:</p>
<ul>
<li>Fold 1: ~70% classe 0, ~30% classe 1 </li>
<li>Fold 2: ~70% classe 0, ~30% classe 1 </li>
<li>Fold 3: ~70% classe 0, ~30% classe 1 </li>
<li>Fold 4: ~70% classe 0, ~30% classe 1 </li>
<li>Fold 5: ~70% classe 0, ~30% classe 1 </li>
</ul>
<p style="margin-top: 15px; font-weight: 600; color: #2e7d32;">
                        Resultado: AvaliaÃ§Ã£o justa e consistente em todos os folds!
                    </p>
</div>
<h3 class="subsection-title">ComparaÃ§Ã£o Visual â€” OrientaÃ§Ã£o do orientador</h3>
<div class="visual-diagram">
<div class="diagram-title">K-Fold vs Stratified K-Fold</div>
<pre class="code-block" data-label="CÃ³digo" style="font-family: monospace; text-align: left; display: inline-block; line-height: 2;">
<strong>Dataset Original:</strong> 70% Classe 0, 30% Classe 1

<strong>K-Fold PadrÃ£o (PODE dar errado):</strong>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fold 1: 65% C0, 35% C1  â† Desbalanceadoâ”‚
â”‚ Fold 2: 75% C0, 25% C1  â† Desbalanceadoâ”‚
â”‚ Fold 3: 68% C0, 32% C1                 â”‚
â”‚ Fold 4: 72% C0, 28% C1                 â”‚
â”‚ Fold 5: 70% C0, 30% C1                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ï¸ InconsistÃªncia entre folds!

<strong>Stratified K-Fold (SEMPRE correto):</strong>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fold 1: 70% C0, 30% C1   Balanceado   â”‚
â”‚ Fold 2: 70% C0, 30% C1   Balanceado   â”‚
â”‚ Fold 3: 70% C0, 30% C1   Balanceado   â”‚
â”‚ Fold 4: 70% C0, 30% C1   Balanceado   â”‚
â”‚ Fold 5: 70% C0, 30% C1   Balanceado   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Proporcionalidade garantida!
</pre>
</div>
<h3 class="subsection-title">Por Que Isso Ã‰ Crucial para HipertensÃ£o â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>Aspecto</th>
<th>K-Fold Simples</th>
<th>Stratified K-Fold</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ProporÃ§Ã£o de Classes</strong></td>
<td style="background: #ffebee;">Varia entre folds</td>
<td style="background: #e8f5e9;">Mantida em todos os folds</td>
</tr>
<tr>
<td><strong>Representatividade</strong></td>
<td style="background: #ffebee;">Alguns folds podem ter muito poucos casos positivos</td>
<td style="background: #e8f5e9;">Todos os folds tÃªm representaÃ§Ã£o adequada</td>
</tr>
<tr>
<td><strong>ConsistÃªncia das MÃ©tricas</strong></td>
<td style="background: #ffebee;">Alta variabilidade</td>
<td style="background: #e8f5e9;">Baixa variabilidade (desvio padrÃ£o menor)</td>
</tr>
<tr>
<td><strong>Confiabilidade</strong></td>
<td style="background: #ffebee;">Moderada</td>
<td style="background: #e8f5e9;">Alta</td>
</tr>
<tr>
<td><strong>Adequado para Desbalanceamento</strong></td>
<td style="background: #ffebee;">NÃƒO</td>
<td style="background: #e8f5e9;">SIM</td>
</tr>
</tbody>
</table>
<h3 class="subsection-title">CÃ³digo: Stratified K-Fold Completo â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># STRATIFIED K-FOLD CROSS-VALIDATION</span>
<span class="code-comment"># VersÃ£o OTIMIZADA para dados desbalanceados</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">from</span> sklearn.model_selection <span class="code-keyword">import</span> StratifiedKFold
<span class="code-keyword">from</span> sklearn.ensemble <span class="code-keyword">import</span> RandomForestClassifier
<span class="code-keyword">from</span> sklearn.metrics <span class="code-keyword">import</span> (
    recall_score, precision_score, fbeta_score,
    roc_auc_score, confusion_matrix
)
<span class="code-keyword">from</span> imblearn.over_sampling <span class="code-keyword">import</span> SMOTE
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># CONFIGURAÃ‡ÃƒO</span>
<span class="code-comment"># ============================================================</span>
K = 5  <span class="code-comment"># NÃºmero de folds</span>
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)
<span class="code-function">print</span>(<span class="code-string">f"STRATIFIED K-FOLD CROSS-VALIDATION (K={K})"</span>)
<span class="code-function">print</span>(<span class="code-string">"Garantindo proporÃ§Ã£o de classes em todos os folds"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

<span class="code-comment"># Ver distribuiÃ§Ã£o original</span>
classe_0_total = (y == 0).sum()
classe_1_total = (y == 1).sum()
prop_original = classe_1_total / len(y)

<span class="code-function">print</span>(<span class="code-string">f"\n DistribuiÃ§Ã£o Original:"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Classe 0: {classe_0_total} ({classe_0_total/len(y)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Classe 1: {classe_1_total} ({classe_1_total/len(y)*100:.1f}%)"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   ProporÃ§Ã£o classe minoritÃ¡ria: {prop_original:.3f}"</span>)

<span class="code-comment"># Configurar Stratified K-Fold</span>
skfold = StratifiedKFold(
    n_splits=K,
    shuffle=<span class="code-keyword">True</span>,
    random_state=42
)

<span class="code-comment"># Listas para armazenar mÃ©tricas e proporÃ§Ãµes</span>
metricas_por_fold = {
    <span class="code-string">'sensibilidade'</span>: [],
    <span class="code-string">'precisao'</span>: [],
    <span class="code-string">'f2_score'</span>: [],
    <span class="code-string">'roc_auc'</span>: [],
    <span class="code-string">'fn'</span>: [],
    <span class="code-string">'fp'</span>: [],
    <span class="code-string">'prop_classe1_treino'</span>: [],  <span class="code-comment"># Para verificar estratificaÃ§Ã£o</span>
<span class="code-string">'prop_classe1_teste'</span>: []
}

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># EXECUTAR STRATIFIED K-FOLD</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">for</span> fold, (train_idx, test_idx) <span class="code-keyword">in</span> <span class="code-function">enumerate</span>(skfold.split(X, y), 1):
    <span class="code-function">print</span>(<span class="code-string">f"\n{'â”€'*80}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" FOLD {fold}/{K}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*80}"</span>)
    
    <span class="code-comment"># 1. Dividir dados (estratificados!)</span>
    X_train_fold = X.iloc[train_idx]
    X_test_fold = X.iloc[test_idx]
    y_train_fold = y.iloc[train_idx]
    y_test_fold = y.iloc[test_idx]
    
    <span class="code-comment"># Verificar estratificaÃ§Ã£o</span>
    prop_treino = y_train_fold.sum() / len(y_train_fold)
    prop_teste = y_test_fold.sum() / len(y_test_fold)
    
    metricas_por_fold[<span class="code-string">'prop_classe1_treino'</span>].append(prop_treino)
    metricas_por_fold[<span class="code-string">'prop_classe1_teste'</span>].append(prop_teste)
    
    <span class="code-function">print</span>(<span class="code-string">f"   Tamanhos:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Treino: {len(X_train_fold)} amostras"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Teste:  {len(X_test_fold)} amostras"</span>)
    
    <span class="code-function">print</span>(<span class="code-string">f"\n   ProporÃ§Ãµes (verificaÃ§Ã£o de estratificaÃ§Ã£o):"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Original:       {prop_original:.3f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Treino fold:    {prop_treino:.3f}  "</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Teste fold:     {prop_teste:.3f}  "</span>)
    
    <span class="code-comment"># 2. Aplicar SMOTE (apenas no treino)</span>
    smote = SMOTE(random_state=42, k_neighbors=5)
    X_train_balanced, y_train_balanced = smote.fit_resample(
        X_train_fold, y_train_fold
    )
    
    <span class="code-function">print</span>(<span class="code-string">f"\n   SMOTE aplicado: {len(X_train_balanced)} amostras balanceadas"</span>)
    
    <span class="code-comment"># 3. Treinar modelo</span>
    modelo = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight=<span class="code-string">'balanced'</span>
    )
    modelo.fit(X_train_balanced, y_train_balanced)
    
    <span class="code-comment"># 4. PrediÃ§Ãµes e mÃ©tricas</span>
    y_pred = modelo.predict(X_test_fold)
    y_proba = modelo.predict_proba(X_test_fold)[:, 1]
    
    sensibilidade = recall_score(y_test_fold, y_pred)
    precisao = precision_score(y_test_fold, y_pred)
    f2 = fbeta_score(y_test_fold, y_pred, beta=2)
    roc_auc = roc_auc_score(y_test_fold, y_proba)
    
    cm = confusion_matrix(y_test_fold, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    <span class="code-comment"># Armazenar</span>
    metricas_por_fold[<span class="code-string">'sensibilidade'</span>].append(sensibilidade)
    metricas_por_fold[<span class="code-string">'precisao'</span>].append(precisao)
    metricas_por_fold[<span class="code-string">'f2_score'</span>].append(f2)
    metricas_por_fold[<span class="code-string">'roc_auc'</span>].append(roc_auc)
    metricas_por_fold[<span class="code-string">'fn'</span>].append(fn)
    metricas_por_fold[<span class="code-string">'fp'</span>].append(fp)
    
    <span class="code-function">print</span>(<span class="code-string">f"\n    Resultados:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      Sensibilidade: {sensibilidade:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      F2-Score:      {f2:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      ROC-AUC:       {roc_auc:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      FN: {fn}  |  FP: {fp}"</span>)

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># ANÃLISE FINAL</span>
<span class="code-comment"># ============================================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">" RESULTADOS FINAIS (STRATIFIED K-FOLD)"</span>)
<span class="code-function">print</span>(<span class="code-string">"="</span>*80)

<span class="code-comment"># Verificar qualidade da estratificaÃ§Ã£o</span>
prop_treino_media = np.mean(metricas_por_fold[<span class="code-string">'prop_classe1_treino'</span>])
prop_treino_std = np.std(metricas_por_fold[<span class="code-string">'prop_classe1_treino'</span>])
prop_teste_media = np.mean(metricas_por_fold[<span class="code-string">'prop_classe1_teste'</span>])
prop_teste_std = np.std(metricas_por_fold[<span class="code-string">'prop_classe1_teste'</span>])

<span class="code-function">print</span>(<span class="code-string">f"\n VERIFICAÃ‡ÃƒO DE ESTRATIFICAÃ‡ÃƒO:"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   ProporÃ§Ã£o original:           {prop_original:.3f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   ProporÃ§Ã£o mÃ©dia (treino):     {prop_treino_media:.3f} Â± {prop_treino_std:.3f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   ProporÃ§Ã£o mÃ©dia (teste):      {prop_teste_media:.3f} Â± {prop_teste_std:.3f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Desvio da original (treino):  {abs(prop_treino_media - prop_original):.4f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Desvio da original (teste):   {abs(prop_teste_media - prop_original):.4f}"</span>)

<span class="code-keyword">if</span> prop_treino_std &lt; 0.01 <span class="code-keyword">and</span> prop_teste_std &lt; 0.01:
    <span class="code-function">print</span>(<span class="code-string">f"\n    EstratificaÃ§Ã£o EXCELENTE (desvio padrÃ£o &lt; 0.01)"</span>)
<span class="code-keyword">else</span>:
    <span class="code-function">print</span>(<span class="code-string">f"\n   ï¸  EstratificaÃ§Ã£o OK mas com alguma variaÃ§Ã£o"</span>)

<span class="code-comment"># MÃ©tricas principais</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'â”€'*80}"</span>)
<span class="code-function">print</span>(<span class="code-string">f" MÃ‰TRICAS PRINCIPAIS:"</span>)
<span class="code-function">print</span>(<span class="code-string">f"{'â”€'*80}"</span>)

<span class="code-keyword">for</span> metrica <span class="code-keyword">in</span> [<span class="code-string">'sensibilidade'</span>, <span class="code-string">'precisao'</span>, <span class="code-string">'f2_score'</span>, <span class="code-string">'roc_auc'</span>]:
    valores = metricas_por_fold[metrica]
    media = np.mean(valores)
    std = np.std(valores)
    
    <span class="code-function">print</span>(<span class="code-string">f"\n{metrica.upper().replace('_', '-')}:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   {media:.4f} Â± {std:.4f}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   Range: [{min(valores):.4f}, {max(valores):.4f}]"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   CV (Coef. VariaÃ§Ã£o): {(std/media)*100:.2f}%"</span>)

<span class="code-comment"># Falsos negativos</span>
fn_valores = metricas_por_fold[<span class="code-string">'fn'</span>]
<span class="code-function">print</span>(<span class="code-string">f"\nFALSOS NEGATIVOS (FN):"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   MÃ©dia: {np.mean(fn_valores):.1f} Â± {np.std(fn_valores):.1f}"</span>)
<span class="code-function">print</span>(<span class="code-string">f"   Range: [{min(fn_valores)}, {max(fn_valores)}]"</span>)

<span class="code-comment"># Salvar resultados</span>
df_resultados = pd.DataFrame(metricas_por_fold)
df_resultados[<span class="code-string">'fold'</span>] = <span class="code-function">range</span>(1, K+1)
df_resultados.to_csv(<span class="code-string">f'stratified_kfold_k{K}_resultados.csv'</span>, index=<span class="code-keyword">False</span>)

<span class="code-function">print</span>(<span class="code-string">f"\n Resultados salvos em: stratified_kfold_k{K}_resultados.csv"</span>)
                </div>
<h3 class="subsection-title">Quando Usar Cada TÃ©cnica â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>SituaÃ§Ã£o</th>
<th>TÃ©cnica Recomendada</th>
<th>Justificativa</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Classes Balanceadas</strong><br/>(50/50 ou prÃ³ximo)</td>
<td>K-Fold simples</td>
<td>EstratificaÃ§Ã£o nÃ£o Ã© necessÃ¡ria</td>
</tr>
<tr style="background: #e8f5e9;">
<td><strong>Classes Desbalanceadas</strong><br/>(70/30, 80/20, etc)</td>
<td><strong>Stratified K-Fold</strong></td>
<td>Garante representatividade em todos os folds</td>
</tr>
<tr>
<td><strong>Problemas de RegressÃ£o</strong></td>
<td>K-Fold simples</td>
<td>NÃ£o hÃ¡ classes para estratificar</td>
</tr>
<tr style="background: #e8f5e9;">
<td><strong>AplicaÃ§Ãµes MÃ©dicas</strong></td>
<td><strong>Stratified K-Fold</strong></td>
<td>Dados mÃ©dicos geralmente desbalanceados</td>
</tr>
<tr style="background: #e8f5e9;">
<td><strong>TCC de HipertensÃ£o</strong></td>
<td><strong>Stratified K-Fold</strong></td>
<td>30% vs 70% = desbalanceamento moderado</td>
</tr>
</tbody>
</table>
<div class="key-takeaway">
<h4>Pontos-Chave do Stratified K-Fold</h4>
<ul>
<li> <strong>Essencial para dados desbalanceados</strong> como hipertensÃ£o</li>
<li> Garante <strong>mesma proporÃ§Ã£o de classes</strong> em todos os folds</li>
<li> Resulta em <strong>menor desvio padrÃ£o</strong> das mÃ©tricas (mais estÃ¡vel)</li>
<li> <strong>Mais confiÃ¡vel</strong> que K-Fold simples para classificaÃ§Ã£o</li>
<li> Use <strong>StratifiedKFold</strong> ao invÃ©s de <strong>KFold</strong> no cÃ³digo</li>
<li> Aplicar <strong>SMOTE em cada fold</strong> apÃ³s a divisÃ£o estratificada</li>
<li> <strong>PadrÃ£o ouro</strong> para validaÃ§Ã£o em ML com classes desbalanceadas</li>
</ul>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" onclick="prevTab()">
                        â† Anterior
                    </button>
<button class="nav-button next" onclick="nextTab()">
                        PrÃ³ximo: ImplementaÃ§Ã£o Final â†’
                    </button>
</div>
</div>
<!-- TAB 6: IMPLEMENTAÃ‡ÃƒO FINAL -->
<div class="tab-content" id="tab6">
<h2 class="section-title">ImplementaÃ§Ã£o Final: CÃ³digo Completo Integrado â€” OrientaÃ§Ã£o do orientador</h2>
<div class="success-box">
<h4> ParabÃ©ns por Chegar AtÃ© Aqui!</h4>
<p>VocÃª aprendeu as 4 tÃ©cnicas avanÃ§adas essenciais:</p>
<ul>
<li> <strong>SMOTE</strong> - Balanceamento sintÃ©tico</li>
<li> <strong>ProporÃ§Ãµes</strong> - OtimizaÃ§Ã£o de divisÃ£o treino/teste</li>
<li> <strong>K-Fold</strong> - ValidaÃ§Ã£o mÃºltipla</li>
<li> <strong>Stratified K-Fold</strong> - Garantia de representatividade</li>
</ul>
<p style="margin-top: 15px; font-weight: 600;">Agora vamos integrar TUDO em um cÃ³digo final completo e pronto para usar no seu TCC!</p>
</div>
<h3 class="subsection-title">Pipeline Completo: Todas as TÃ©cnicas Juntas â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="Python">
<span class="code-comment"># ============================================================</span>
<span class="code-comment"># PIPELINE COMPLETO DE VALIDAÃ‡ÃƒO</span>
<span class="code-comment"># Integra: SMOTE + ProporÃ§Ãµes + Stratified K-Fold</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns

<span class="code-keyword">from</span> sklearn.model_selection <span class="code-keyword">import</span> StratifiedKFold, train_test_split
<span class="code-keyword">from</span> sklearn.ensemble <span class="code-keyword">import</span> RandomForestClassifier
<span class="code-keyword">from</span> sklearn.metrics <span class="code-keyword">import</span> (
    recall_score, precision_score, f1_score, fbeta_score,
    roc_auc_score, confusion_matrix, classification_report
)
<span class="code-keyword">from</span> imblearn.over_sampling <span class="code-keyword">import</span> SMOTE

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># FUNÃ‡ÃƒO PRINCIPAL: AvaliaÃ§Ã£o Completa</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">def</span> <span class="code-function">avaliar_modelo_completo</span>(
    X, y,
    modelo,
    test_sizes=[0.25],  <span class="code-comment"># Lista de proporÃ§Ãµes para testar</span>
    k_folds=5,          <span class="code-comment"># NÃºmero de folds</span>
    random_state=42
):
    <span class="code-string">"""
    AvaliaÃ§Ã£o completa com todas as tÃ©cnicas avanÃ§adas.
    
    ParÃ¢metros:
    -----------
    X : DataFrame/array
        Features
    y : Series/array
        Target
    modelo : estimator
        Modelo de ML (ex: RandomForestClassifier)
    test_sizes : list
        Lista de proporÃ§Ãµes de teste para comparar
    k_folds : int
        NÃºmero de folds para validaÃ§Ã£o cruzada
    random_state : int
        Seed para reprodutibilidade
    
    Retorna:
    --------
    dict com todos os resultados
    """</span>
<span class="code-function">print</span>(<span class="code-string">"="</span>*90)
    <span class="code-function">print</span>(<span class="code-string">" PIPELINE COMPLETO DE AVALIAÃ‡ÃƒO"</span>)
    <span class="code-function">print</span>(<span class="code-string">"   TÃ©cnicas: SMOTE + ProporÃ§Ãµes + Stratified K-Fold"</span>)
    <span class="code-function">print</span>(<span class="code-string">"="</span>*90)
    
    resultados_globais = {}
    
    <span class="code-comment"># ========================================</span>
<span class="code-comment"># ETAPA 1: Testar Diferentes ProporÃ§Ãµes</span>
<span class="code-comment"># ========================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n ETAPA 1: Comparando {len(test_sizes)} proporÃ§Ãµes de treino/teste"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*90}"</span>)
    
    resultados_proporcoes = []
    
    <span class="code-keyword">for</span> test_size <span class="code-keyword">in</span> test_sizes:
        train_pct = int((1 - test_size) * 100)
        test_pct = int(test_size * 100)
        
        <span class="code-function">print</span>(<span class="code-string">f"\n   Testando proporÃ§Ã£o: {train_pct}/{test_pct}"</span>)
        
        <span class="code-comment"># Dividir dados</span>
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=test_size,
            random_state=random_state,
            stratify=y
        )
        
        <span class="code-comment"># SMOTE</span>
        smote = SMOTE(random_state=random_state, k_neighbors=5)
        X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)
        
        <span class="code-comment"># Treinar e avaliar</span>
        modelo.fit(X_train_bal, y_train_bal)
        y_pred = modelo.predict(X_test)
        y_proba = modelo.predict_proba(X_test)[:, 1]
        
        <span class="code-comment"># MÃ©tricas</span>
        sens = recall_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred)
        f2 = fbeta_score(y_test, y_pred, beta=2)
        auc = roc_auc_score(y_test, y_proba)
        
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        resultados_proporcoes.append({
            <span class="code-string">'ProporÃ§Ã£o'</span>: <span class="code-string">f'{train_pct}/{test_pct}'</span>,
            <span class="code-string">'Sensibilidade'</span>: sens,
            <span class="code-string">'PrecisÃ£o'</span>: prec,
            <span class="code-string">'F2-Score'</span>: f2,
            <span class="code-string">'ROC-AUC'</span>: auc,
            <span class="code-string">'FN'</span>: fn,
            <span class="code-string">'FP'</span>: fp
        })
        
        <span class="code-function">print</span>(<span class="code-string">f"      Sensibilidade: {sens:.4f} | F2: {f2:.4f} | FN: {fn}"</span>)
    
    df_proporcoes = pd.DataFrame(resultados_proporcoes)
    melhor_prop_idx = df_proporcoes[<span class="code-string">'F2-Score'</span>].idxmax()
    melhor_prop = df_proporcoes.iloc[melhor_prop_idx]
    
    <span class="code-function">print</span>(<span class="code-string">f"\n    Melhor proporÃ§Ã£o: {melhor_prop['ProporÃ§Ã£o']}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      F2-Score: {melhor_prop['F2-Score']:.4f}"</span>)
    
    resultados_globais[<span class="code-string">'proporcoes'</span>] = df_proporcoes
    resultados_globais[<span class="code-string">'melhor_proporcao'</span>] = melhor_prop[<span class="code-string">'ProporÃ§Ã£o'</span>]
    
    <span class="code-comment"># ========================================</span>
<span class="code-comment"># ETAPA 2: Stratified K-Fold na Melhor ProporÃ§Ã£o</span>
<span class="code-comment"># ========================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*90}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" ETAPA 2: Stratified {k_folds}-Fold na melhor proporÃ§Ã£o"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*90}"</span>)
    
    <span class="code-comment"># Usar melhor test_size</span>
    melhor_test_size = test_sizes[melhor_prop_idx]
    
    <span class="code-comment"># Configurar Stratified K-Fold</span>
    skfold = StratifiedKFold(
        n_splits=k_folds,
        shuffle=<span class="code-keyword">True</span>,
        random_state=random_state
    )
    
    metricas_kfold = {
        <span class="code-string">'sensibilidade'</span>: [],
        <span class="code-string">'precisao'</span>: [],
        <span class="code-string">'f1_score'</span>: [],
        <span class="code-string">'f2_score'</span>: [],
        <span class="code-string">'roc_auc'</span>: [],
        <span class="code-string">'fn'</span>: [],
        <span class="code-string">'fp'</span>: []
    }
    
    <span class="code-comment"># Executar K-Fold</span>
<span class="code-keyword">for</span> fold, (train_idx, test_idx) <span class="code-keyword">in</span> <span class="code-function">enumerate</span>(skfold.split(X, y), 1):
        <span class="code-function">print</span>(<span class="code-string">f"\n   Fold {fold}/{k_folds}..."</span>, end=<span class="code-string">" "</span>)
        
        <span class="code-comment"># Dividir</span>
        X_train_fold = X.iloc[train_idx]
        X_test_fold = X.iloc[test_idx]
        y_train_fold = y.iloc[train_idx]
        y_test_fold = y.iloc[test_idx]
        
        <span class="code-comment"># SMOTE</span>
        smote = SMOTE(random_state=random_state, k_neighbors=5)
        X_train_bal, y_train_bal = smote.fit_resample(X_train_fold, y_train_fold)
        
        <span class="code-comment"># Treinar</span>
        modelo_fold = modelo.__class__(**modelo.get_params())
        modelo_fold.fit(X_train_bal, y_train_bal)
        
        <span class="code-comment"># PrediÃ§Ãµes</span>
        y_pred = modelo_fold.predict(X_test_fold)
        y_proba = modelo_fold.predict_proba(X_test_fold)[:, 1]
        
        <span class="code-comment"># MÃ©tricas</span>
        metricas_kfold[<span class="code-string">'sensibilidade'</span>].append(recall_score(y_test_fold, y_pred))
        metricas_kfold[<span class="code-string">'precisao'</span>].append(precision_score(y_test_fold, y_pred))
        metricas_kfold[<span class="code-string">'f1_score'</span>].append(f1_score(y_test_fold, y_pred))
        metricas_kfold[<span class="code-string">'f2_score'</span>].append(fbeta_score(y_test_fold, y_pred, beta=2))
        metricas_kfold[<span class="code-string">'roc_auc'</span>].append(roc_auc_score(y_test_fold, y_proba))
        
        cm = confusion_matrix(y_test_fold, y_pred)
        tn, fp, fn, tp = cm.ravel()
        metricas_kfold[<span class="code-string">'fn'</span>].append(fn)
        metricas_kfold[<span class="code-string">'fp'</span>].append(fp)
        
        <span class="code-function">print</span>(<span class="code-string">f"Sens: {metricas_kfold['sensibilidade'][-1]:.4f}"</span>)
    
    <span class="code-comment"># Calcular estatÃ­sticas</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'â”€'*90}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" RESULTADOS FINAIS ({k_folds}-Fold Cross-Validation)"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'â”€'*90}"</span>)
    
    resumo_kfold = {}
    <span class="code-keyword">for</span> metrica, valores <span class="code-keyword">in</span> metricas_kfold.items():
        media = np.mean(valores)
        std = np.std(valores)
        resumo_kfold[metrica] = {
            <span class="code-string">'media'</span>: media,
            <span class="code-string">'std'</span>: std,
            <span class="code-string">'min'</span>: <span class="code-function">min</span>(valores),
            <span class="code-string">'max'</span>: <span class="code-function">max</span>(valores)
        }
        
        <span class="code-keyword">if</span> metrica <span class="code-keyword">not</span> <span class="code-keyword">in</span> [<span class="code-string">'fn'</span>, <span class="code-string">'fp'</span>]:
            <span class="code-function">print</span>(<span class="code-string">f"\n   {metrica.upper().replace('_', '-')}:"</span>)
            <span class="code-function">print</span>(<span class="code-string">f"      {media:.4f} Â± {std:.4f}"</span>)
            <span class="code-function">print</span>(<span class="code-string">f"      Range: [{min(valores):.4f}, {max(valores):.4f}]"</span>)
    
    <span class="code-comment"># FN e FP</span>
<span class="code-function">print</span>(<span class="code-string">f"\n   FALSOS NEGATIVOS (FN):"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"      {resumo_kfold['fn']['media']:.1f} Â± {resumo_kfold['fn']['std']:.1f}"</span>)
    
    resultados_globais[<span class="code-string">'kfold'</span>] = pd.DataFrame(metricas_kfold)
    resultados_globais[<span class="code-string">'resumo_kfold'</span>] = resumo_kfold
    
    <span class="code-comment"># ========================================</span>
<span class="code-comment"># ETAPA 3: AvaliaÃ§Ã£o Final</span>
<span class="code-comment"># ========================================</span>
<span class="code-function">print</span>(<span class="code-string">f"\n{'='*90}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f" AVALIAÃ‡ÃƒO FINAL DO TCC"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"{'='*90}"</span>)
    
    sens_media = resumo_kfold[<span class="code-string">'sensibilidade'</span>][<span class="code-string">'media'</span>]
    f2_media = resumo_kfold[<span class="code-string">'f2_score'</span>][<span class="code-string">'media'</span>]
    
    <span class="code-function">print</span>(<span class="code-string">f"\n TÃ©cnicas Aplicadas:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"    SMOTE para balanceamento"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"    Testadas {len(test_sizes)} proporÃ§Ãµes treino/teste"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"    Stratified {k_folds}-Fold Cross-Validation"</span>)
    
    <span class="code-function">print</span>(<span class="code-string">f"\n Melhor ConfiguraÃ§Ã£o:"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   ProporÃ§Ã£o: {melhor_prop['ProporÃ§Ã£o']}"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   Sensibilidade: {sens_media:.4f} ({sens_media*100:.2f}%)"</span>)
    <span class="code-function">print</span>(<span class="code-string">f"   F2-Score: {f2_media:.4f}"</span>)
    
    <span class="code-keyword">if</span> sens_media &gt;= 0.90:
        <span class="code-function">print</span>(<span class="code-string">f"\n    META ATINGIDA: Sensibilidade â‰¥ 90%!"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"    Modelo adequado para aplicaÃ§Ã£o clÃ­nica"</span>)
    <span class="code-keyword">else</span>:
        <span class="code-function">print</span>(<span class="code-string">f"\n   ï¸  Sensibilidade abaixo da meta de 90%"</span>)
        <span class="code-function">print</span>(<span class="code-string">f"   Considere: ajustar hiperparÃ¢metros ou threshold"</span>)
    
    <span class="code-function">print</span>(<span class="code-string">f"\n{'='*90}"</span>)
    
    <span class="code-keyword">return</span> resultados_globais

<span class="code-comment"># ============================================================</span>
<span class="code-comment"># EXEMPLO DE USO</span>
<span class="code-comment"># ============================================================</span>
<span class="code-keyword">if</span> __name__ == <span class="code-string">"__main__"</span>:
    <span class="code-comment"># Carregar seus dados</span>
    df = pd.read_csv(<span class="code-string">'Hypertension-risk-model-main.csv'</span>)
    
    <span class="code-comment"># Preparar dados (ajuste conforme seu cÃ³digo)</span>
    X = df.drop(<span class="code-string">'Risk'</span>, axis=1)
    y = df[<span class="code-string">'Risk'</span>]
    
    <span class="code-comment"># Definir modelo</span>
    modelo = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight=<span class="code-string">'balanced'</span>
    )
    
    <span class="code-comment"># Executar avaliaÃ§Ã£o completa</span>
    resultados = avaliar_modelo_completo(
        X, y,
        modelo=modelo,
        test_sizes=[0.20, 0.25, 0.30],  <span class="code-comment"># Testar 3 proporÃ§Ãµes</span>
        k_folds=5,                       <span class="code-comment"># 5-fold</span>
        random_state=42
    )
    
    <span class="code-comment"># Salvar resultados</span>
    resultados[<span class="code-string">'proporcoes'</span>].to_csv(<span class="code-string">'resultados_proporcoes.csv'</span>, index=<span class="code-keyword">False</span>)
    resultados[<span class="code-string">'kfold'</span>].to_csv(<span class="code-string">'resultados_kfold.csv'</span>, index=<span class="code-keyword">False</span>)
    
    <span class="code-function">print</span>(<span class="code-string">"\n Resultados salvos!"</span>)
                </div>
<h3 class="subsection-title">Resumo: O Que Este CÃ³digo Faz â€” OrientaÃ§Ã£o do orientador</h3>
<div class="step-card">
<div class="step-number">1</div>
<div class="step-content">
<div class="step-title">Testa MÃºltiplas ProporÃ§Ãµes</div>
<p>Compara 60/40, 70/30, 75/25, 80/20 (ou as que vocÃª definir) com SMOTE aplicado em cada uma, identificando a melhor proporÃ§Ã£o baseada em F2-Score.</p>
</div>
</div>
<div class="step-card">
<div class="step-number">2</div>
<div class="step-content">
<div class="step-title">Executa Stratified K-Fold</div>
<p>Usa a melhor proporÃ§Ã£o encontrada e realiza Stratified K-Fold (5 ou 10 folds) para obter mÃ©dia Â± desvio padrÃ£o de todas as mÃ©tricas.</p>
</div>
</div>
<div class="step-card">
<div class="step-number">3</div>
<div class="step-content">
<div class="step-title">Aplica SMOTE em Cada Etapa</div>
<p>SMOTE Ã© aplicado de forma correta: apenas no conjunto de treino de cada fold, nunca no teste.</p>
</div>
</div>
<div class="step-card">
<div class="step-number">4</div>
<div class="step-content">
<div class="step-title">Gera RelatÃ³rio Completo</div>
<p>Imprime anÃ¡lise detalhada e salva resultados em CSVs para incluir no TCC.</p>
</div>
</div>
<h3 class="subsection-title">Como Usar no Seu TCC â€” OrientaÃ§Ã£o do orientador</h3>
<div class="info-box">
<h4> Passos para ImplementaÃ§Ã£o</h4>
<ol>
<li><strong>Substituir o cÃ³digo atual de avaliaÃ§Ã£o</strong> pela funÃ§Ã£o <code>avaliar_modelo_completo()</code></li>
<li><strong>Executar com seu dataset</strong> e modelo Random Forest (ou outro)</li>
<li><strong>Analisar os resultados</strong> salvos nos CSVs</li>
<li><strong>Incluir no TCC:</strong>
<ul>
<li>Tabela comparando proporÃ§Ãµes</li>
<li>Resultados do K-Fold com mÃ©dia Â± desvio padrÃ£o</li>
<li>Justificativa da proporÃ§Ã£o escolhida</li>
<li>DiscussÃ£o sobre confiabilidade (baixo desvio padrÃ£o)</li>
</ul>
</li>
<li><strong>Na defesa, destacar:</strong> Uso de tÃ©cnicas avanÃ§adas (SMOTE, Stratified K-Fold), rigor metodolÃ³gico, resultados robustos com intervalo de confianÃ§a</li>
</ol>
</div>
<h3 class="subsection-title">ComparaÃ§Ã£o: Antes vs Depois â€” OrientaÃ§Ã£o do orientador</h3>
<table class="comparison-table">
<thead>
<tr>
<th>Aspecto</th>
<th>CÃ³digo Atual (TCC)</th>
<th>CÃ³digo Proposto (Com TÃ©cnicas)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Balanceamento</strong></td>
<td>RandomOverSampler (duplicaÃ§Ã£o)</td>
<td style="background: #e8f5e9;"><strong>SMOTE</strong> (interpolaÃ§Ã£o sintÃ©tica)</td>
</tr>
<tr>
<td><strong>ProporÃ§Ã£o Treino/Teste</strong></td>
<td>75/25 fixo (sem justificativa)</td>
<td style="background: #e8f5e9;">Testa mÃºltiplas, <strong>escolhe a melhor</strong></td>
</tr>
<tr>
<td><strong>ValidaÃ§Ã£o</strong></td>
<td>1 Ãºnica divisÃ£o</td>
<td style="background: #e8f5e9;"><strong>Stratified 5-Fold</strong> (5 validaÃ§Ãµes)</td>
</tr>
<tr>
<td><strong>Confiabilidade</strong></td>
<td>Baixa (resultados variam muito)</td>
<td style="background: #e8f5e9;">Alta (mÃ©dia Â± desvio padrÃ£o)</td>
</tr>
<tr>
<td><strong>EstratificaÃ§Ã£o</strong></td>
<td>Sim (apenas na divisÃ£o inicial)</td>
<td style="background: #e8f5e9;">Sim (<strong>em todos os folds</strong>)</td>
</tr>
<tr>
<td><strong>Rigor MetodolÃ³gico</strong></td>
<td>BÃ¡sico</td>
<td style="background: #e8f5e9;"><strong>AvanÃ§ado</strong> (estado-da-arte)</td>
</tr>
<tr>
<td><strong>Tempo de ExecuÃ§Ã£o</strong></td>
<td>~1 minuto</td>
<td style="background: #fff3cd;">~5-10 minutos (vale a pena!)</td>
</tr>
<tr>
<td><strong>Qualidade para Banca</strong></td>
<td>Adequado</td>
<td style="background: #e8f5e9;"><strong>Excelente</strong> (impressiona banca)</td>
</tr>
</tbody>
</table>
<h3 class="subsection-title">Exemplo de SaÃ­da do CÃ³digo â€” OrientaÃ§Ã£o do orientador</h3>
<div class="code-block" data-label="CÃ³digo" style="background: #1e1e1e; color: #d4d4d4;">
<span style="color: #4EC9B0;">==========================================================================================</span>
<span style="color: #4EC9B0;"> PIPELINE COMPLETO DE AVALIAÃ‡ÃƒO</span>
<span style="color: #4EC9B0;">   TÃ©cnicas: SMOTE + ProporÃ§Ãµes + Stratified K-Fold</span>
<span style="color: #4EC9B0;">==========================================================================================</span>
<span style="color: #DCDCAA;"> ETAPA 1: Comparando 3 proporÃ§Ãµes de treino/teste</span>
<span style="color: #608B4E;">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>

   Testando proporÃ§Ã£o: 80/20
      Sensibilidade: 0.9245 | F2: 0.9156 | FN: 18

   Testando proporÃ§Ã£o: 75/25
      Sensibilidade: 0.9333 | F2: 0.9201 | FN: 20

   Testando proporÃ§Ã£o: 70/30
      Sensibilidade: 0.9412 | F2: 0.9287 | FN: 17

   <span style="color: #4EC9B0;"> Melhor proporÃ§Ã£o: 70/30</span>
      F2-Score: 0.9287

<span style="color: #4EC9B0;">==========================================================================================</span>
<span style="color: #DCDCAA;"> ETAPA 2: Stratified 5-Fold na melhor proporÃ§Ã£o</span>
<span style="color: #608B4E;">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>

   Fold 1/5... Sens: 0.9400
   Fold 2/5... Sens: 0.9250
   Fold 3/5... Sens: 0.9500
   Fold 4/5... Sens: 0.9350
   Fold 5/5... Sens: 0.9300

<span style="color: #608B4E;">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span style="color: #DCDCAA;"> RESULTADOS FINAIS (5-Fold Cross-Validation)</span>
<span style="color: #608B4E;">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>

   SENSIBILIDADE:
      <span style="color: #4EC9B0;">0.9360 Â± 0.0089</span>
      Range: [0.9250, 0.9500]

   F2-SCORE:
      <span style="color: #4EC9B0;">0.9287 Â± 0.0065</span>
      Range: [0.9201, 0.9356]

   ROC-AUC:
      <span style="color: #4EC9B0;">0.9523 Â± 0.0042</span>
      Range: [0.9468, 0.9580]

   FALSOS NEGATIVOS (FN):
      <span style="color: #4EC9B0;">19.2 Â± 2.1</span>
<span style="color: #4EC9B0;">==========================================================================================</span>
<span style="color: #4EC9B0;"> AVALIAÃ‡ÃƒO FINAL DO TCC</span>
<span style="color: #4EC9B0;">==========================================================================================</span>

 TÃ©cnicas Aplicadas:
    SMOTE para balanceamento
    Testadas 3 proporÃ§Ãµes treino/teste
    Stratified 5-Fold Cross-Validation

 Melhor ConfiguraÃ§Ã£o:
   ProporÃ§Ã£o: 70/30
   Sensibilidade: 0.9360 (93.60%)
   F2-Score: 0.9287

   <span style="color: #4EC9B0;"> META ATINGIDA: Sensibilidade â‰¥ 90%!</span>
<span style="color: #4EC9B0;"> Modelo adequado para aplicaÃ§Ã£o clÃ­nica</span>
<span style="color: #4EC9B0;">==========================================================================================</span>
<span style="color: #4EC9B0;"> Resultados salvos!</span>
</div>
<div class="key-takeaway">
<h4>SÃ­ntese orientativa</h4>
<p><strong>ParabÃ©ns! VocÃª dominou as 4 tÃ©cnicas avanÃ§adas essenciais!</strong></p>
<p style="margin-top: 15px;"><strong>O que vocÃª aprendeu:</strong></p>
<ul>
<li> <strong>SMOTE</strong> cria amostras sintÃ©ticas por interpolaÃ§Ã£o (melhor que duplicaÃ§Ã£o)</li>
<li> <strong>Testar proporÃ§Ãµes</strong> ajuda a encontrar divisÃ£o Ã³tima treino/teste</li>
<li> <strong>K-Fold</strong> fornece mÃ©dia Â± desvio padrÃ£o (mais confiÃ¡vel)</li>
<li> <strong>Stratified K-Fold</strong> garante representatividade em dados desbalanceados</li>
</ul>
<p style="margin-top: 15px;"><strong>Impacto esperado no TCC:</strong></p>
<ul>
<li> Sensibilidade: <strong>+4-7%</strong> (de ~88% para ~92-95%)</li>
<li> F2-Score: <strong>+3-6%</strong></li>
<li> Confiabilidade: <strong>Muito maior</strong> (mÃ©dia de 5-10 validaÃ§Ãµes)</li>
<li> Rigor: <strong>Estado-da-arte</strong> (impressiona banca)</li>
</ul>
<p style="margin-top: 15px;"><strong>PrÃ³ximos passos:</strong></p>
<ol>
<li>Copiar o cÃ³digo final para seu notebook</li>
<li>Executar com seus dados</li>
<li>Analisar resultados e gerar grÃ¡ficos</li>
<li>Documentar no TCC com justificativas</li>
<li>Preparar defesa destacando tÃ©cnicas avanÃ§adas</li>
</ol>
<p style="margin-top: 20px; padding: 15px; background: #fff59d; border-left: 5px solid #fbc02d; font-weight: 600;">
                         Dica Final: Na defesa, enfatize que vocÃª nÃ£o apenas aplicou tÃ©cnicas bÃ¡sicas, mas implementou um pipeline completo de validaÃ§Ã£o com mÃ©todos estado-da-arte, demonstrando profundo conhecimento de Machine Learning e rigor cientÃ­fico!
                    </p>
</div>
<div class="navigation-buttons">
<button class="nav-button prev" onclick="prevTab()">
                        â† Anterior
                    </button>
<button class="nav-button next" disabled="" style="opacity: 0.5;">
                        Tutorial Completo! 
                    </button>
</div>
</div>
</div>
</div>
<script>
        let currentTab = 1;
        const totalTabs = 6;

        function openTab(evt, tabId) {
            // Esconder todos os conteÃºdos
            const contents = document.getElementsByClassName('tab-content');
            for (let content of contents) {
                content.classList.remove('active');
            }

            // Remover classe active de todos os tabs
            const tabs = document.getElementsByClassName('tab');
            for (let tab of tabs) {
                tab.classList.remove('active');
            }

            // Mostrar conteÃºdo selecionado
            document.getElementById(tabId).classList.add('active');
            
            // Adicionar classe active ao tab clicado
            if (evt && evt.currentTarget) {
                evt.currentTarget.classList.add('active');
            }

            // Atualizar currentTab
            currentTab = parseInt(tabId.replace('tab', ''));

            // Atualizar barra de progresso
            updateProgress();

            // Scroll to top
            window.scrollTo(0, 0);
        }

        function nextTab() {
            if (currentTab < totalTabs) {
                // Marcar tab atual como completo
                const tabs = document.getElementsByClassName('tab');
                tabs[currentTab - 1].classList.add('completed');

                currentTab++;
                openTab(null, 'tab' + currentTab);
            }
        }

        function prevTab() {
            if (currentTab > 1) {
                currentTab--;
                openTab(null, 'tab' + currentTab);
            }
        }

        function updateProgress() {
            const progress = (currentTab / totalTabs) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        // Inicializar
        updateProgress();
    </script>
</body>
</html>